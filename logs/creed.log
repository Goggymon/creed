2026-02-16 22:22:40,827 [INFO] Boot Seqeunce Started
2026-02-16 22:22:40,827 [INFO] Boot Complete
2026-02-17 10:46:11,817 [INFO] Boot Seqeunce Started
2026-02-17 10:46:11,822 [INFO] Boot Complete
2026-02-17 11:24:39,551 [INFO] Boot Seqeunce Started
2026-02-17 11:24:47,475 [INFO] Boot Complete
2026-02-17 11:54:29,175 [INFO] Boot Seqeunce Started
2026-02-17 11:56:00,792 [INFO] Boot Complete
2026-02-17 11:56:05,144 [INFO] Boot Seqeunce Started
2026-02-17 11:56:15,961 [INFO] Boot Complete
2026-02-17 12:07:04,242 [INFO] Boot Seqeunce Started
2026-02-17 12:10:48,037 [INFO] Boot Seqeunce Started
2026-02-17 12:13:52,742 [INFO] Boot Complete
2026-02-17 12:29:12,660 [INFO] Boot Seqeunce Started
2026-02-17 12:33:39,565 [INFO] Boot Seqeunce Started
2026-02-17 12:36:51,368 [INFO] Boot Complete
2026-02-17 13:24:49,538 [INFO] Boot Seqeunce Started
2026-02-17 13:26:17,473 [INFO] Boot Complete
2026-02-17 14:09:34,889 [INFO] Boot Seqeunce Started
2026-02-17 14:10:32,978 [INFO] Boot Complete
2026-02-17 15:09:25,263 [INFO] Boot Seqeunce Started
2026-02-17 15:09:45,307 [INFO] Boot Seqeunce Started
2026-02-17 15:14:16,950 [INFO] Boot Complete
2026-02-17 15:19:57,416 [INFO] Boot Seqeunce Started
2026-02-17 15:21:02,480 [INFO] Boot Complete
2026-02-17 15:21:30,524 [INFO] Boot Seqeunce Started
2026-02-17 15:25:36,389 [INFO] Boot Complete
2026-02-17 15:35:44,561 [INFO] Boot Seqeunce Started
2026-02-17 15:37:01,998 [INFO] Boot Complete
2026-02-17 15:38:49,770 [INFO] Boot Seqeunce Started
2026-02-17 15:39:16,327 [INFO] Boot Complete
2026-02-17 15:41:23,544 [INFO] Boot Seqeunce Started
2026-02-17 15:42:40,403 [INFO] Boot Complete
2026-02-17 15:43:52,173 [INFO] Boot Seqeunce Started
2026-02-17 15:44:38,797 [INFO] Boot Complete
2026-02-17 15:47:07,527 [INFO] Boot Seqeunce Started
2026-02-17 15:47:51,776 [INFO] Boot Complete
2026-02-17 15:48:41,575 [INFO] Boot Seqeunce Started
2026-02-17 15:48:55,882 [INFO] Boot Complete
2026-02-17 15:49:19,922 [INFO] Boot Seqeunce Started
2026-02-17 15:49:26,779 [INFO] Boot Complete
2026-02-17 15:49:40,548 [INFO] Boot Seqeunce Started
2026-02-17 15:50:54,400 [INFO] Boot Complete
2026-02-17 16:05:40,226 [INFO] Boot Seqeunce Started
2026-02-17 16:11:30,675 [INFO] Boot Complete
2026-02-18 12:24:30,408 [INFO] Boot Seqeunce Started
2026-02-18 12:26:14,412 [INFO] Boot Complete
2026-02-18 12:29:01,356 [INFO] Boot Seqeunce Started
2026-02-18 12:29:13,843 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-aa8789f9-ea80-4953-b13b-2cc8967b8b41', 'content': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what is quantum mechanics'}], 'model': 'gpt-4o-mini', 'temperature': 0.7}}
2026-02-18 12:29:13,848 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2026-02-18 12:29:13,849 [DEBUG] connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-18 12:29:13,887 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x702049ef98a0>
2026-02-18 12:29:13,887 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x70204ad75d40> server_hostname='api.openai.com' timeout=5.0
2026-02-18 12:29:13,902 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x702049ef9930>
2026-02-18 12:29:13,902 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-18 12:29:13,903 [DEBUG] send_request_headers.complete
2026-02-18 12:29:13,903 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-18 12:29:13,903 [DEBUG] send_request_body.complete
2026-02-18 12:29:13,903 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-18 12:29:14,597 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 18 Feb 2026 06:59:14 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_eafb5c3b38a5498aa7134b1fa890e18c'), (b'x-openai-proxy-wasm', b'v0.1'), (b'Server', b'cloudflare'), (b'cf-cache-status', b'DYNAMIC'), (b'set-cookie', b'__cf_bm=hkLYyWh2sE7ZHm.fks_99hs8IN6okR0DirqXcpZp67c-1771397953.896955-1.0.1.1-RU.b6oQu2rZpMaRPEnQANZC0vR9Zu.iNWMd8wpjtrcG8baSsu6MITeRlvSkvqWrlygvpFYGABTaEu6ySYStFUePHUgiAOZXHBhKULf60rDkLlT0NwkJfFr2LkDRbrYKf; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 07:29:14 GMT'), (b'set-cookie', b'_cfuvid=4Mg4aXArpZ_VwmZJeOUdmGJvGtngjpOEqPCSwNdlGAM-1771397953.896955-1.0.1.1-yMKCT_y1EPGur04YZpIo.FvzRqfp4iCdUAH9sfo9JoQ; HttpOnly; SameSite=None; Secure; Path=/; Domain=api.openai.com'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'CF-RAY', b'9cfba3fbdf15ad7b-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-18 12:29:14,602 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2026-02-18 12:29:14,602 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-18 12:29:14,602 [DEBUG] receive_response_body.complete
2026-02-18 12:29:14,602 [DEBUG] response_closed.started
2026-02-18 12:29:14,602 [DEBUG] response_closed.complete
2026-02-18 12:29:14,602 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Wed, 18 Feb 2026 06:59:14 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_eafb5c3b38a5498aa7134b1fa890e18c'), ('x-openai-proxy-wasm', 'v0.1'), ('server', 'cloudflare'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=hkLYyWh2sE7ZHm.fks_99hs8IN6okR0DirqXcpZp67c-1771397953.896955-1.0.1.1-RU.b6oQu2rZpMaRPEnQANZC0vR9Zu.iNWMd8wpjtrcG8baSsu6MITeRlvSkvqWrlygvpFYGABTaEu6ySYStFUePHUgiAOZXHBhKULf60rDkLlT0NwkJfFr2LkDRbrYKf; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 07:29:14 GMT'), ('set-cookie', '_cfuvid=4Mg4aXArpZ_VwmZJeOUdmGJvGtngjpOEqPCSwNdlGAM-1771397953.896955-1.0.1.1-yMKCT_y1EPGur04YZpIo.FvzRqfp4iCdUAH9sfo9JoQ; HttpOnly; SameSite=None; Secure; Path=/; Domain=api.openai.com'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('cf-ray', '9cfba3fbdf15ad7b-DEL'), ('alt-svc', 'h3=":443"; ma=86400')])
2026-02-18 12:29:14,602 [DEBUG] request_id: req_eafb5c3b38a5498aa7134b1fa890e18c
2026-02-18 12:29:14,602 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/creed-storage/creed/venv/lib/python3.10/site-packages/openai/_base_client.py", line 1050, in request
    response.raise_for_status()
  File "/creed-storage/creed/venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2026-02-18 12:29:14,608 [DEBUG] Retrying due to status code 429
2026-02-18 12:29:14,608 [DEBUG] 2 retries left
2026-02-18 12:29:14,608 [INFO] Retrying request to /chat/completions in 0.416529 seconds
2026-02-18 12:29:15,047 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-aa8789f9-ea80-4953-b13b-2cc8967b8b41', 'content': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what is quantum mechanics'}], 'model': 'gpt-4o-mini', 'temperature': 0.7}}
2026-02-18 12:29:15,048 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2026-02-18 12:29:15,048 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-18 12:29:15,049 [DEBUG] send_request_headers.complete
2026-02-18 12:29:15,049 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-18 12:29:15,050 [DEBUG] send_request_body.complete
2026-02-18 12:29:15,050 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-18 12:29:15,747 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 18 Feb 2026 06:59:15 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_f2e3c7aa152744299996d09f41cc6517'), (b'x-openai-proxy-wasm', b'v0.1'), (b'Server', b'cloudflare'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-RAY', b'9cfba4030cacad7b-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-18 12:29:15,747 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2026-02-18 12:29:15,748 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-18 12:29:15,748 [DEBUG] receive_response_body.complete
2026-02-18 12:29:15,748 [DEBUG] response_closed.started
2026-02-18 12:29:15,748 [DEBUG] response_closed.complete
2026-02-18 12:29:15,748 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 18 Feb 2026 06:59:15 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_f2e3c7aa152744299996d09f41cc6517', 'x-openai-proxy-wasm': 'v0.1', 'server': 'cloudflare', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-ray': '9cfba4030cacad7b-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-18 12:29:15,748 [DEBUG] request_id: req_f2e3c7aa152744299996d09f41cc6517
2026-02-18 12:29:15,748 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/creed-storage/creed/venv/lib/python3.10/site-packages/openai/_base_client.py", line 1050, in request
    response.raise_for_status()
  File "/creed-storage/creed/venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2026-02-18 12:29:15,748 [DEBUG] Retrying due to status code 429
2026-02-18 12:29:15,748 [DEBUG] 1 retry left
2026-02-18 12:29:15,748 [INFO] Retrying request to /chat/completions in 0.943136 seconds
2026-02-18 12:29:16,695 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-aa8789f9-ea80-4953-b13b-2cc8967b8b41', 'content': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what is quantum mechanics'}], 'model': 'gpt-4o-mini', 'temperature': 0.7}}
2026-02-18 12:29:16,696 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2026-02-18 12:29:16,696 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-18 12:29:16,697 [DEBUG] send_request_headers.complete
2026-02-18 12:29:16,697 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-18 12:29:16,697 [DEBUG] send_request_body.complete
2026-02-18 12:29:16,697 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-18 12:29:17,365 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 18 Feb 2026 06:59:17 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_f17e52f4f336428b93d578a9894fb64c'), (b'x-openai-proxy-wasm', b'v0.1'), (b'Server', b'cloudflare'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-RAY', b'9cfba40d5fc7ad7b-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-18 12:29:17,365 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2026-02-18 12:29:17,365 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-18 12:29:17,365 [DEBUG] receive_response_body.complete
2026-02-18 12:29:17,365 [DEBUG] response_closed.started
2026-02-18 12:29:17,365 [DEBUG] response_closed.complete
2026-02-18 12:29:17,365 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 18 Feb 2026 06:59:17 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_f17e52f4f336428b93d578a9894fb64c', 'x-openai-proxy-wasm': 'v0.1', 'server': 'cloudflare', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-ray': '9cfba40d5fc7ad7b-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-18 12:29:17,365 [DEBUG] request_id: req_f17e52f4f336428b93d578a9894fb64c
2026-02-18 12:29:17,365 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/creed-storage/creed/venv/lib/python3.10/site-packages/openai/_base_client.py", line 1050, in request
    response.raise_for_status()
  File "/creed-storage/creed/venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2026-02-18 12:29:17,366 [DEBUG] Re-raising status error
2026-02-18 12:31:19,768 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2427de91-0fe0-44ca-9f7b-0883c006cfcc', 'content': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what is quantum mechanics'}, {'role': 'user', 'content': 'ext'}], 'model': 'gpt-4o-mini', 'temperature': 0.7}}
2026-02-18 12:31:19,769 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2026-02-18 12:31:19,769 [DEBUG] close.started
2026-02-18 12:31:19,770 [DEBUG] close.complete
2026-02-18 12:31:19,770 [DEBUG] connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-18 12:31:19,799 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x702049d9d360>
2026-02-18 12:31:19,799 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x70204ad75d40> server_hostname='api.openai.com' timeout=5.0
2026-02-18 12:31:19,818 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x702049d9d3c0>
2026-02-18 12:31:19,818 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-18 12:31:19,819 [DEBUG] send_request_headers.complete
2026-02-18 12:31:19,819 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-18 12:31:19,819 [DEBUG] send_request_body.complete
2026-02-18 12:31:19,819 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-18 12:31:20,121 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 18 Feb 2026 07:01:20 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_249f20befea24b78a5ffb7f2d3397cc0'), (b'x-openai-proxy-wasm', b'v0.1'), (b'Server', b'cloudflare'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-RAY', b'9cfba70edd2e45ec-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-18 12:31:20,122 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2026-02-18 12:31:20,122 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-18 12:31:20,122 [DEBUG] receive_response_body.complete
2026-02-18 12:31:20,122 [DEBUG] response_closed.started
2026-02-18 12:31:20,122 [DEBUG] response_closed.complete
2026-02-18 12:31:20,122 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 18 Feb 2026 07:01:20 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_249f20befea24b78a5ffb7f2d3397cc0', 'x-openai-proxy-wasm': 'v0.1', 'server': 'cloudflare', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-ray': '9cfba70edd2e45ec-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-18 12:31:20,122 [DEBUG] request_id: req_249f20befea24b78a5ffb7f2d3397cc0
2026-02-18 12:31:20,122 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/creed-storage/creed/venv/lib/python3.10/site-packages/openai/_base_client.py", line 1050, in request
    response.raise_for_status()
  File "/creed-storage/creed/venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2026-02-18 12:31:20,122 [DEBUG] Retrying due to status code 429
2026-02-18 12:31:20,122 [DEBUG] 2 retries left
2026-02-18 12:31:20,122 [INFO] Retrying request to /chat/completions in 0.446862 seconds
2026-02-18 12:31:20,573 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2427de91-0fe0-44ca-9f7b-0883c006cfcc', 'content': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what is quantum mechanics'}, {'role': 'user', 'content': 'ext'}], 'model': 'gpt-4o-mini', 'temperature': 0.7}}
2026-02-18 12:31:20,573 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2026-02-18 12:31:20,574 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-18 12:31:20,575 [DEBUG] send_request_headers.complete
2026-02-18 12:31:20,575 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-18 12:31:20,576 [DEBUG] send_request_body.complete
2026-02-18 12:31:20,576 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-18 12:31:20,876 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 18 Feb 2026 07:01:20 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_26443ace7f524fb7bcda3a881e694fbf'), (b'x-openai-proxy-wasm', b'v0.1'), (b'Server', b'cloudflare'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-RAY', b'9cfba7138fa145ec-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-18 12:31:20,876 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2026-02-18 12:31:20,877 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-18 12:31:20,877 [DEBUG] receive_response_body.complete
2026-02-18 12:31:20,877 [DEBUG] response_closed.started
2026-02-18 12:31:20,877 [DEBUG] response_closed.complete
2026-02-18 12:31:20,877 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 18 Feb 2026 07:01:20 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_26443ace7f524fb7bcda3a881e694fbf', 'x-openai-proxy-wasm': 'v0.1', 'server': 'cloudflare', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-ray': '9cfba7138fa145ec-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-18 12:31:20,877 [DEBUG] request_id: req_26443ace7f524fb7bcda3a881e694fbf
2026-02-18 12:31:20,877 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/creed-storage/creed/venv/lib/python3.10/site-packages/openai/_base_client.py", line 1050, in request
    response.raise_for_status()
  File "/creed-storage/creed/venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2026-02-18 12:31:20,877 [DEBUG] Retrying due to status code 429
2026-02-18 12:31:20,877 [DEBUG] 1 retry left
2026-02-18 12:31:20,877 [INFO] Retrying request to /chat/completions in 0.884938 seconds
2026-02-18 12:31:21,763 [DEBUG] Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2427de91-0fe0-44ca-9f7b-0883c006cfcc', 'content': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what is quantum mechanics'}, {'role': 'user', 'content': 'ext'}], 'model': 'gpt-4o-mini', 'temperature': 0.7}}
2026-02-18 12:31:21,763 [DEBUG] Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2026-02-18 12:31:21,763 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-18 12:31:21,766 [DEBUG] send_request_headers.complete
2026-02-18 12:31:21,766 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-18 12:31:21,767 [DEBUG] send_request_body.complete
2026-02-18 12:31:21,767 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-18 12:31:22,484 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 18 Feb 2026 07:01:22 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_dfd57803858045d395d8964365d3e811'), (b'x-openai-proxy-wasm', b'v0.1'), (b'Server', b'cloudflare'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-RAY', b'9cfba71b0ebb45ec-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-18 12:31:22,484 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2026-02-18 12:31:22,484 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-18 12:31:22,484 [DEBUG] receive_response_body.complete
2026-02-18 12:31:22,484 [DEBUG] response_closed.started
2026-02-18 12:31:22,484 [DEBUG] response_closed.complete
2026-02-18 12:31:22,484 [DEBUG] HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Wed, 18 Feb 2026 07:01:22 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_dfd57803858045d395d8964365d3e811', 'x-openai-proxy-wasm': 'v0.1', 'server': 'cloudflare', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-ray': '9cfba71b0ebb45ec-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-18 12:31:22,484 [DEBUG] request_id: req_dfd57803858045d395d8964365d3e811
2026-02-18 12:31:22,484 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/creed-storage/creed/venv/lib/python3.10/site-packages/openai/_base_client.py", line 1050, in request
    response.raise_for_status()
  File "/creed-storage/creed/venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2026-02-18 12:31:22,484 [DEBUG] Re-raising status error
2026-02-18 12:40:52,716 [INFO] Boot Complete
2026-02-18 13:00:52,944 [INFO] Boot Seqeunce Started
2026-02-18 13:01:01,182 [DEBUG] Starting new HTTP connection (1): 192.168.68.60:11434
2026-02-18 13:07:19,691 [INFO] Boot Complete
2026-02-18 13:22:47,594 [INFO] Boot Seqeunce Started
2026-02-18 13:22:54,711 [DEBUG] Starting new HTTP connection (1): 192.168.68.60:11434
2026-02-18 13:23:12,945 [DEBUG] http://192.168.68.60:11434 "POST /api/chat HTTP/1.1" 200 493
2026-02-18 13:23:43,379 [INFO] Boot Complete
2026-02-18 13:29:20,263 [INFO] Boot Seqeunce Started
2026-02-18 13:29:21,729 [DEBUG] Starting new HTTP connection (1): 192.168.68.60:11434
2026-02-18 13:30:05,845 [DEBUG] http://192.168.68.60:11434 "POST /api/chat HTTP/1.1" 200 326
2026-02-18 13:30:14,230 [DEBUG] Starting new HTTP connection (1): 192.168.68.60:11434
2026-02-18 13:30:25,041 [DEBUG] http://192.168.68.60:11434 "POST /api/chat HTTP/1.1" 200 565
2026-02-18 13:30:42,032 [DEBUG] Starting new HTTP connection (1): 192.168.68.60:11434
2026-02-18 13:30:53,880 [DEBUG] http://192.168.68.60:11434 "POST /api/chat HTTP/1.1" 200 623
2026-02-18 13:31:48,402 [INFO] Boot Complete
2026-02-18 16:10:03,195 [INFO] Boot Seqeunce Started
2026-02-18 16:10:17,323 [DEBUG] Starting new HTTP connection (1): 192.168.68.60:11434
2026-02-18 16:10:49,373 [DEBUG] http://192.168.68.60:11434 "POST /api/chat HTTP/1.1" 200 1180
2026-02-18 20:04:30,945 [INFO] Boot Seqeunce Started
2026-02-18 20:04:53,398 [DEBUG] Starting new HTTP connection (1): 192.168.68.60:11434
2026-02-18 20:05:53,660 [DEBUG] Starting new HTTP connection (1): 192.168.68.60:11434
2026-02-18 20:06:09,158 [INFO] Boot Complete
2026-02-19 21:33:06,394 [INFO] Boot Seqeunce Started
2026-02-19 21:33:56,025 [INFO] Boot Complete
2026-02-19 21:35:19,022 [INFO] Boot Seqeunce Started
2026-02-19 21:36:18,419 [INFO] Boot Complete
2026-02-19 21:36:52,179 [INFO] Boot Seqeunce Started
2026-02-19 21:36:56,407 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 21:41:13,987 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 21:41:31,883 [INFO] Boot Complete
2026-02-19 21:43:24,469 [INFO] Boot Seqeunce Started
2026-02-19 21:43:28,789 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 21:43:50,542 [DEBUG] http://localhost:11434 "POST /api/chat HTTP/1.1" 200 339
2026-02-19 21:44:09,655 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 21:46:52,344 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 21:55:21,412 [INFO] Boot Seqeunce Started
2026-02-19 21:55:27,301 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 21:58:35,188 [INFO] Boot Complete
2026-02-19 21:58:36,001 [INFO] Boot Seqeunce Started
2026-02-19 21:58:40,042 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 21:58:45,709 [DEBUG] http://localhost:11434 "POST /api/chat HTTP/1.1" 200 379
2026-02-19 22:04:22,881 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 22:04:33,335 [DEBUG] http://localhost:11434 "POST /api/chat HTTP/1.1" 200 582
2026-02-19 22:04:57,177 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 22:05:20,200 [DEBUG] http://localhost:11434 "POST /api/chat HTTP/1.1" 200 841
2026-02-19 22:05:49,619 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 22:06:12,085 [INFO] Boot Seqeunce Started
2026-02-19 22:06:18,380 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 22:06:21,622 [DEBUG] http://localhost:11434 "POST /api/chat HTTP/1.1" 200 322
2026-02-19 22:08:52,696 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 22:09:22,556 [INFO] Boot Seqeunce Started
2026-02-19 22:09:27,045 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 22:10:37,665 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 22:10:41,711 [INFO] Boot Complete
2026-02-19 22:12:23,218 [INFO] Boot Seqeunce Started
2026-02-19 22:12:43,890 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 22:14:09,456 [INFO] Boot Seqeunce Started
2026-02-19 22:14:13,006 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 22:22:09,579 [INFO] Boot Complete
2026-02-19 22:22:20,123 [INFO] Boot Seqeunce Started
2026-02-19 22:22:22,413 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 22:26:23,947 [INFO] Boot Seqeunce Started
2026-02-19 22:26:27,876 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-19 22:27:15,452 [INFO] Boot Seqeunce Started
2026-02-19 22:27:16,856 [INFO] Boot Complete
2026-02-20 13:16:50,793 [INFO] Boot Seqeunce Started
2026-02-20 13:16:58,495 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-20 13:18:06,637 [INFO] Boot Seqeunce Started
2026-02-20 13:18:08,291 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-20 13:18:14,206 [DEBUG] http://localhost:11434 "POST /api/chat HTTP/1.1" 200 329
2026-02-20 13:22:16,006 [INFO] Boot Complete
2026-02-20 13:22:59,628 [INFO] Boot Seqeunce Started
2026-02-20 13:23:04,582 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-20 13:24:07,647 [INFO] Boot Seqeunce Started
2026-02-20 13:24:09,829 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-20 13:27:17,321 [INFO] Boot Seqeunce Started
2026-02-20 13:33:19,465 [INFO] Boot Seqeunce Started
2026-02-20 13:34:13,102 [INFO] Boot Seqeunce Started
2026-02-20 13:34:15,373 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-20 13:35:12,631 [INFO] Boot Complete
2026-02-21 03:01:53,145 [INFO] Boot Seqeunce Started
2026-02-21 03:02:24,648 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-21 03:02:42,765 [INFO] Boot Complete
2026-02-21 03:03:43,071 [INFO] Boot Seqeunce Started
2026-02-21 03:03:59,883 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-21 03:04:02,297 [DEBUG] http://localhost:11434 "POST /api/chat HTTP/1.1" 200 None
2026-02-21 03:04:38,343 [INFO] Boot Seqeunce Started
2026-02-21 03:04:42,117 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-21 03:04:44,606 [DEBUG] http://localhost:11434 "POST /api/chat HTTP/1.1" 200 None
2026-02-21 03:05:08,828 [INFO] Boot Complete
2026-02-21 03:08:49,610 [INFO] Boot Seqeunce Started
2026-02-21 03:09:01,397 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-21 03:09:11,797 [INFO] Boot Complete
2026-02-21 03:13:47,789 [INFO] Boot Seqeunce Started
2026-02-21 03:14:43,497 [INFO] Boot Complete
2026-02-21 03:15:00,862 [INFO] Boot Seqeunce Started
2026-02-21 03:15:05,801 [DEBUG] Starting new HTTP connection (1): localhost:11434
2026-02-21 03:15:27,963 [INFO] Boot Complete
2026-02-24 12:38:47,015 [INFO] Boot Seqeunce Started
2026-02-24 12:38:53,810 [INFO] Boot Complete
2026-02-24 12:48:44,888 [INFO] Boot Seqeunce Started
2026-02-24 12:48:52,663 [INFO] Boot Seqeunce Started
2026-02-24 12:48:59,387 [INFO] Boot Seqeunce Started
2026-02-24 12:49:39,878 [INFO] Boot Seqeunce Started
2026-02-24 12:50:05,387 [INFO] Boot Seqeunce Started
2026-02-24 12:50:22,253 [INFO] Boot Seqeunce Started
2026-02-24 12:51:11,173 [INFO] Boot Seqeunce Started
2026-02-24 12:53:15,410 [INFO] Boot Seqeunce Started
2026-02-24 12:53:52,336 [INFO] Boot Seqeunce Started
2026-02-24 13:03:25,809 [INFO] Boot Seqeunce Started
2026-02-24 13:03:33,529 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-a216b86e-2304-48bd-aad7-31189327366d', 'json_data': {'messages': [{'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello.'}, {'role': 'user', 'content': 'whats good'}], 'model': 'llama3-8b-8192', 'stream': True}}
2026-02-24 13:03:33,609 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:03:33,609 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:03:33,655 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000207B3F797E0>
2026-02-24 13:03:33,655 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x00000207B35F00C0> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:03:33,655 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000207B3F79870>
2026-02-24 13:03:33,655 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:03:33,655 [DEBUG] send_request_headers.complete
2026-02-24 13:03:33,655 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:03:33,671 [DEBUG] send_request_body.complete
2026-02-24 13:03:33,671 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:03:33,719 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Tue, 24 Feb 2026 07:33:33 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'275'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-request-id', b'req_01kj792kt9fn1s89hc1w7p1m42'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'set-cookie', b'__cf_bm=UA69HZmYb7K.jcuQpYMoP1lqGaSfjR0frbT5smLi1tQ-1771918413.6277852-1.0.1.1-JQR9EDHxkOLEivUug63hzCIFQ.JBkC095uKOqzmd7fMdCjS9oWlKB7iQUqikFx5oitCVt0cN5I0_F1hs2f.pVodLMp0NdkXIIBBGT98COsfTJUWfWpQbdI9sbGHqmqaS; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:03:33 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2d46852a7c5957-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:03:33,719 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2026-02-24 13:03:33,719 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "400 Bad Request" Headers({'date': 'Tue, 24 Feb 2026 07:33:33 GMT', 'content-type': 'application/json', 'content-length': '275', 'connection': 'keep-alive', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-request-id': 'req_01kj792kt9fn1s89hc1w7p1m42', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=UA69HZmYb7K.jcuQpYMoP1lqGaSfjR0frbT5smLi1tQ-1771918413.6277852-1.0.1.1-JQR9EDHxkOLEivUug63hzCIFQ.JBkC095uKOqzmd7fMdCjS9oWlKB7iQUqikFx5oitCVt0cN5I0_F1hs2f.pVodLMp0NdkXIIBBGT98COsfTJUWfWpQbdI9sbGHqmqaS; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:03:33 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2d46852a7c5957-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:03:33,719 [DEBUG] Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "D:\CREED\creed\venv\lib\site-packages\groq\_base_client.py", line 1024, in request
    response.raise_for_status()
  File "D:\CREED\creed\venv\lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2026-02-24 13:03:33,719 [DEBUG] Not retrying
2026-02-24 13:03:33,719 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:03:33,719 [DEBUG] receive_response_body.complete
2026-02-24 13:03:33,719 [DEBUG] response_closed.started
2026-02-24 13:03:33,719 [DEBUG] response_closed.complete
2026-02-24 13:03:33,719 [DEBUG] Re-raising status error
2026-02-24 13:08:23,925 [INFO] Boot Seqeunce Started
2026-02-24 13:08:31,523 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d6b37a58-35df-4dc5-b520-290124ae3e5a', 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:08:31,605 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:08:31,605 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:08:31,653 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F23F797E0>
2026-02-24 13:08:31,653 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023F235F4040> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:08:31,671 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F23F79870>
2026-02-24 13:08:31,671 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:08:31,671 [DEBUG] send_request_headers.complete
2026-02-24 13:08:31,671 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:08:31,671 [DEBUG] send_request_body.complete
2026-02-24 13:08:31,671 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:08:31,756 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 07:38:31 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5961'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'389ms'), (b'x-request-id', b'req_01kj79bptcfw5as5c9n2jm1vgx'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'set-cookie', b'__cf_bm=p9vNTxXVLdDxJs7oZzvxa6pPArMKejdZY9Av1qDKcJM-1771918711.6196542-1.0.1.1-JCPAe8_cqqqeh4TMZDIcgmEJoIYcAoCX_MV9jl62asCw7G.lrRMLIGEeTa7fiEvR0XJZPsp7fyAvEwdN3uNJRw6CuXVdWcjkkexv2rJgGEDQUBha66Ky33ISvNmPIofz; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:08:31 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2d4dcb9c6b54c0-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:08:31,756 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:08:31,756 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 07:38:31 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5961', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '389ms', 'x-request-id': 'req_01kj79bptcfw5as5c9n2jm1vgx', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=p9vNTxXVLdDxJs7oZzvxa6pPArMKejdZY9Av1qDKcJM-1771918711.6196542-1.0.1.1-JCPAe8_cqqqeh4TMZDIcgmEJoIYcAoCX_MV9jl62asCw7G.lrRMLIGEeTa7fiEvR0XJZPsp7fyAvEwdN3uNJRw6CuXVdWcjkkexv2rJgGEDQUBha66Ky33ISvNmPIofz; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:08:31 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2d4dcb9c6b54c0-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:08:31,756 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:08:31,804 [DEBUG] receive_response_body.complete
2026-02-24 13:08:31,804 [DEBUG] response_closed.started
2026-02-24 13:08:31,804 [DEBUG] response_closed.complete
2026-02-24 13:08:36,294 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d562e871-c547-42cb-8173-17f076b536f0', 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}, {'role': 'assistant', 'content': "I'm functioning properly. What can I help you with today?"}, {'role': 'user', 'content': 'whatmodel are you?'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:08:36,294 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:08:36,294 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:08:36,294 [DEBUG] send_request_headers.complete
2026-02-24 13:08:36,294 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:08:36,294 [DEBUG] send_request_body.complete
2026-02-24 13:08:36,294 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:08:36,383 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 07:38:36 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'5933'), (b'x-ratelimit-reset-requests', b'12s'), (b'x-ratelimit-reset-tokens', b'670ms'), (b'x-request-id', b'req_01kj79bvayfwcssw7zf9ht7ggt'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2d4de88af554c0-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:08:36,383 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:08:36,383 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 07:38:36 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '5933', 'x-ratelimit-reset-requests': '12s', 'x-ratelimit-reset-tokens': '670ms', 'x-request-id': 'req_01kj79bvayfwcssw7zf9ht7ggt', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2d4de88af554c0-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:08:36,384 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:08:36,444 [DEBUG] receive_response_body.complete
2026-02-24 13:08:36,445 [DEBUG] response_closed.started
2026-02-24 13:08:36,445 [DEBUG] response_closed.complete
2026-02-24 13:08:44,397 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ff99ba2e-135e-45b3-933d-08d89f15993d', 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}, {'role': 'assistant', 'content': "I'm functioning properly. What can I help you with today?"}, {'role': 'user', 'content': 'whatmodel are you?'}, {'role': 'assistant', 'content': "I'm an AI model developed by Meta AI. I'm a type of large language model, specifically a transformer-based model. My architecture is based on the BERT (Bidirectional Encoder Representations from Transformers) model."}, {'role': 'user', 'content': 'whats your name?'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:08:44,398 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:08:44,398 [DEBUG] close.started
2026-02-24 13:08:44,398 [DEBUG] close.complete
2026-02-24 13:08:44,398 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:08:44,421 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F240001F0>
2026-02-24 13:08:44,421 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023F235F4040> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:08:44,421 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F24000250>
2026-02-24 13:08:44,421 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:08:44,421 [DEBUG] send_request_headers.complete
2026-02-24 13:08:44,421 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:08:44,421 [DEBUG] send_request_body.complete
2026-02-24 13:08:44,421 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:08:44,515 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 07:38:44 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'5874'), (b'x-ratelimit-reset-requests', b'12s'), (b'x-ratelimit-reset-tokens', b'1.26s'), (b'x-request-id', b'req_01kj79c38ze8nbdz66e0ncmmr9'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2d4e1b5e1251de-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:08:44,516 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:08:44,516 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 07:38:44 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '5874', 'x-ratelimit-reset-requests': '12s', 'x-ratelimit-reset-tokens': '1.26s', 'x-request-id': 'req_01kj79c38ze8nbdz66e0ncmmr9', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2d4e1b5e1251de-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:08:44,516 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:08:44,552 [DEBUG] receive_response_body.complete
2026-02-24 13:08:44,553 [DEBUG] response_closed.started
2026-02-24 13:08:44,553 [DEBUG] response_closed.complete
2026-02-24 13:09:06,623 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ad9a85d0-0511-4b25-9e44-bd802d2a564a', 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}, {'role': 'assistant', 'content': "I'm functioning properly. What can I help you with today?"}, {'role': 'user', 'content': 'whatmodel are you?'}, {'role': 'assistant', 'content': "I'm an AI model developed by Meta AI. I'm a type of large language model, specifically a transformer-based model. My architecture is based on the BERT (Bidirectional Encoder Representations from Transformers) model."}, {'role': 'user', 'content': 'whats your name?'}, {'role': 'assistant', 'content': 'I don\'t have a personal name, but I\'m often referred to as Llama. Llama stands for "Large Language Model Meta AI."'}, {'role': 'user', 'content': 'tell me about quantum mechanics'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:09:06,623 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:09:06,623 [DEBUG] close.started
2026-02-24 13:09:06,623 [DEBUG] close.complete
2026-02-24 13:09:06,623 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:09:06,633 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F240018D0>
2026-02-24 13:09:06,633 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023F235F4040> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:09:06,647 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F24001930>
2026-02-24 13:09:06,647 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:09:06,649 [DEBUG] send_request_headers.complete
2026-02-24 13:09:06,649 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:09:06,649 [DEBUG] send_request_body.complete
2026-02-24 13:09:06,649 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:09:06,739 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 07:39:06 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5830'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'1.7s'), (b'x-request-id', b'req_01kj79crz9e36tcptn0ygt1bgn'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2d4ea63b408aee-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:09:06,739 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:09:06,739 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 07:39:06 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5830', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '1.7s', 'x-request-id': 'req_01kj79crz9e36tcptn0ygt1bgn', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2d4ea63b408aee-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:09:06,739 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:09:07,366 [DEBUG] receive_response_body.complete
2026-02-24 13:09:07,366 [DEBUG] response_closed.started
2026-02-24 13:09:07,366 [DEBUG] response_closed.complete
2026-02-24 13:09:21,647 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d83bfc7a-786e-490a-bc32-c0a576196f1c', 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}, {'role': 'assistant', 'content': "I'm functioning properly. What can I help you with today?"}, {'role': 'user', 'content': 'whatmodel are you?'}, {'role': 'assistant', 'content': "I'm an AI model developed by Meta AI. I'm a type of large language model, specifically a transformer-based model. My architecture is based on the BERT (Bidirectional Encoder Representations from Transformers) model."}, {'role': 'user', 'content': 'whats your name?'}, {'role': 'assistant', 'content': 'I don\'t have a personal name, but I\'m often referred to as Llama. Llama stands for "Large Language Model Meta AI."'}, {'role': 'user', 'content': 'tell me about quantum mechanics'}, {'role': 'assistant', 'content': "Quantum mechanics is a branch of physics that studies the behavior of matter and energy at an atomic and subatomic level. It's a fundamental aspect of the physical world that has been extensively studied and experimented with. Here's an overview:\n\n**Key principles:**\n\n1. **Wave-particle duality**: Quantum objects, such as electrons, can exhibit both wave-like and particle-like behavior depending on how they're observed.\n2. **Uncertainty principle**: It's impossible to know certain properties of a quantum system, like position and momentum, simultaneously with infinite precision.\n3. **Superposition**: Quantum objects can exist in multiple states simultaneously.\n4. **Entanglement**: Quantum objects can become connected in a way that their properties are correlated, even when separated by large distances.\n5. **Probabilistic nature**: Quantum mechanics is based on probabilities rather than definite outcomes.\n\n**Theories and models:**\n\n1. **Schrdinger equation**: A mathematical equation that describes the time-evolution of a quantum system.\n2. **Dirac equation**: A quantum equation that describes the behavior of fermions (particles with half-integer spin).\n3. **Quantum field theory**: A framework for describing the behavior of fundamental particles and forces in terms of fields that permeate space.\n\n**Experimental evidence:**\n\n1. **Double-slit experiment**: A classic experiment that demonstrated the wave-like behavior of electrons.\n2. **Quantum Eraser experiment**: A variation of the double-slit experiment that shows the effects of entanglement.\n3. **Quantum computing and cryptography**: Experiments that have demonstrated the potential of quantum computing and the security of quantum encryption.\n\n**Implications:**\n\n1. **Quantum computing**: Quantum systems can potentially solve certain problems much faster than classical computers.\n2. **Quantum cryptography**: Quantum systems can enable secure communication over long distances.\n3. **Quantum cosmology**: Quantum mechanics has implications for our understanding of the early universe and the origin of space-time.\n\n**Challenges and open questions:**\n\n1. **Interpretation of quantum mechanics**: There's ongoing debate about the fundamental nature of reality and how to interpret the mathematical formalism of quantum mechanics.\n2. **Quantum gravity**: The integration of quantum mechanics and general relativity is an active area of research.\n3. **Scalability**: Quantum systems are often fragile and difficult to scale up, making it challenging to build practical devices.\n\nThis is just a brief introduction to quantum mechanics. If you have specific questions or topics you'd like to explore further, feel free to ask!"}, {'role': 'user', 'content': 'wow. are you able to solve complex integrals?'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:09:21,647 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:09:21,647 [DEBUG] close.started
2026-02-24 13:09:21,647 [DEBUG] close.complete
2026-02-24 13:09:21,647 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:09:21,671 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F23F7B820>
2026-02-24 13:09:21,671 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023F235F4040> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:09:21,678 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F23F7B8E0>
2026-02-24 13:09:21,678 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:09:21,678 [DEBUG] send_request_headers.complete
2026-02-24 13:09:21,678 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:09:21,678 [DEBUG] send_request_body.complete
2026-02-24 13:09:21,678 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:09:21,756 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 07:39:21 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5287'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'7.13s'), (b'x-request-id', b'req_01kj79d7n3fyqr95fwtb5cneyq'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2d4f042e391043-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:09:21,756 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:09:21,756 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 07:39:21 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5287', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '7.13s', 'x-request-id': 'req_01kj79d7n3fyqr95fwtb5cneyq', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2d4f042e391043-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:09:21,756 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:09:22,181 [DEBUG] receive_response_body.complete
2026-02-24 13:09:22,181 [DEBUG] response_closed.started
2026-02-24 13:09:22,181 [DEBUG] response_closed.complete
2026-02-24 13:09:38,366 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-06fd2069-4399-48cc-b34f-13620e545c41', 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}, {'role': 'assistant', 'content': "I'm functioning properly. What can I help you with today?"}, {'role': 'user', 'content': 'whatmodel are you?'}, {'role': 'assistant', 'content': "I'm an AI model developed by Meta AI. I'm a type of large language model, specifically a transformer-based model. My architecture is based on the BERT (Bidirectional Encoder Representations from Transformers) model."}, {'role': 'user', 'content': 'whats your name?'}, {'role': 'assistant', 'content': 'I don\'t have a personal name, but I\'m often referred to as Llama. Llama stands for "Large Language Model Meta AI."'}, {'role': 'user', 'content': 'tell me about quantum mechanics'}, {'role': 'assistant', 'content': "Quantum mechanics is a branch of physics that studies the behavior of matter and energy at an atomic and subatomic level. It's a fundamental aspect of the physical world that has been extensively studied and experimented with. Here's an overview:\n\n**Key principles:**\n\n1. **Wave-particle duality**: Quantum objects, such as electrons, can exhibit both wave-like and particle-like behavior depending on how they're observed.\n2. **Uncertainty principle**: It's impossible to know certain properties of a quantum system, like position and momentum, simultaneously with infinite precision.\n3. **Superposition**: Quantum objects can exist in multiple states simultaneously.\n4. **Entanglement**: Quantum objects can become connected in a way that their properties are correlated, even when separated by large distances.\n5. **Probabilistic nature**: Quantum mechanics is based on probabilities rather than definite outcomes.\n\n**Theories and models:**\n\n1. **Schrdinger equation**: A mathematical equation that describes the time-evolution of a quantum system.\n2. **Dirac equation**: A quantum equation that describes the behavior of fermions (particles with half-integer spin).\n3. **Quantum field theory**: A framework for describing the behavior of fundamental particles and forces in terms of fields that permeate space.\n\n**Experimental evidence:**\n\n1. **Double-slit experiment**: A classic experiment that demonstrated the wave-like behavior of electrons.\n2. **Quantum Eraser experiment**: A variation of the double-slit experiment that shows the effects of entanglement.\n3. **Quantum computing and cryptography**: Experiments that have demonstrated the potential of quantum computing and the security of quantum encryption.\n\n**Implications:**\n\n1. **Quantum computing**: Quantum systems can potentially solve certain problems much faster than classical computers.\n2. **Quantum cryptography**: Quantum systems can enable secure communication over long distances.\n3. **Quantum cosmology**: Quantum mechanics has implications for our understanding of the early universe and the origin of space-time.\n\n**Challenges and open questions:**\n\n1. **Interpretation of quantum mechanics**: There's ongoing debate about the fundamental nature of reality and how to interpret the mathematical formalism of quantum mechanics.\n2. **Quantum gravity**: The integration of quantum mechanics and general relativity is an active area of research.\n3. **Scalability**: Quantum systems are often fragile and difficult to scale up, making it challenging to build practical devices.\n\nThis is just a brief introduction to quantum mechanics. If you have specific questions or topics you'd like to explore further, feel free to ask!"}, {'role': 'user', 'content': 'wow. are you able to solve complex integrals?'}, {'role': 'assistant', 'content': "Yes, I'm capable of solving complex integrals, but with some limitations. I can:\n\n1. **Symbolically integrate**: I can use techniques like integration by parts, substitution, and integration by partial fractions to solve simple to moderately complex integrals.\n2. **Use numerical methods**: I can use numerical integration methods like Simpson's rule, trapezoidal rule, and Gaussian quadrature to approximate the value of an integral.\n3. **Apply special functions**: I'm familiar with special functions like gamma function, beta function, and error function, which can be used to simplify certain integrals.\n\nHowever, I'm not a replacement for a professional mathematician or a dedicated computer algebra system (CAS). I can struggle with:\n\n1. **Highly complex integrals**: Integrals that involve multiple nested integrals, fractional orders, or highly nonlinear functions can be challenging for me.\n2. **Non-standard notation**: If the integral is written in an unconventional or non-standard notation, I may have difficulty understanding it.\n3. **Advanced mathematical techniques**: Techniques like contour integration, residue calculus, or advanced differential equations may require more specialized knowledge than I possess.\n\nFeel free to provide an integral you'd like me to solve, and I'll do my best to help you."}, {'role': 'user', 'content': 'how can i import images for you?'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:09:38,366 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:09:38,366 [DEBUG] close.started
2026-02-24 13:09:38,366 [DEBUG] close.complete
2026-02-24 13:09:38,366 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:09:38,377 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F24001150>
2026-02-24 13:09:38,377 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023F235F4040> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:09:38,392 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F240011B0>
2026-02-24 13:09:38,392 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:09:38,393 [DEBUG] send_request_headers.complete
2026-02-24 13:09:38,393 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:09:38,393 [DEBUG] send_request_body.complete
2026-02-24 13:09:38,393 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:09:38,474 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 07:39:38 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5013'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'9.87s'), (b'x-request-id', b'req_01kj79dqzde4vb71ssaaynxjwm'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2d4f6cafc28e74-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:09:38,474 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:09:38,474 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 07:39:38 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5013', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '9.87s', 'x-request-id': 'req_01kj79dqzde4vb71ssaaynxjwm', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2d4f6cafc28e74-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:09:38,474 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:09:39,032 [DEBUG] receive_response_body.complete
2026-02-24 13:09:39,032 [DEBUG] response_closed.started
2026-02-24 13:09:39,032 [DEBUG] response_closed.complete
2026-02-24 13:09:52,609 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-3f671e11-5cac-4dc1-833f-4e4c549e785c', 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}, {'role': 'assistant', 'content': "I'm functioning properly. What can I help you with today?"}, {'role': 'user', 'content': 'whatmodel are you?'}, {'role': 'assistant', 'content': "I'm an AI model developed by Meta AI. I'm a type of large language model, specifically a transformer-based model. My architecture is based on the BERT (Bidirectional Encoder Representations from Transformers) model."}, {'role': 'user', 'content': 'whats your name?'}, {'role': 'assistant', 'content': 'I don\'t have a personal name, but I\'m often referred to as Llama. Llama stands for "Large Language Model Meta AI."'}, {'role': 'user', 'content': 'tell me about quantum mechanics'}, {'role': 'assistant', 'content': "Quantum mechanics is a branch of physics that studies the behavior of matter and energy at an atomic and subatomic level. It's a fundamental aspect of the physical world that has been extensively studied and experimented with. Here's an overview:\n\n**Key principles:**\n\n1. **Wave-particle duality**: Quantum objects, such as electrons, can exhibit both wave-like and particle-like behavior depending on how they're observed.\n2. **Uncertainty principle**: It's impossible to know certain properties of a quantum system, like position and momentum, simultaneously with infinite precision.\n3. **Superposition**: Quantum objects can exist in multiple states simultaneously.\n4. **Entanglement**: Quantum objects can become connected in a way that their properties are correlated, even when separated by large distances.\n5. **Probabilistic nature**: Quantum mechanics is based on probabilities rather than definite outcomes.\n\n**Theories and models:**\n\n1. **Schrdinger equation**: A mathematical equation that describes the time-evolution of a quantum system.\n2. **Dirac equation**: A quantum equation that describes the behavior of fermions (particles with half-integer spin).\n3. **Quantum field theory**: A framework for describing the behavior of fundamental particles and forces in terms of fields that permeate space.\n\n**Experimental evidence:**\n\n1. **Double-slit experiment**: A classic experiment that demonstrated the wave-like behavior of electrons.\n2. **Quantum Eraser experiment**: A variation of the double-slit experiment that shows the effects of entanglement.\n3. **Quantum computing and cryptography**: Experiments that have demonstrated the potential of quantum computing and the security of quantum encryption.\n\n**Implications:**\n\n1. **Quantum computing**: Quantum systems can potentially solve certain problems much faster than classical computers.\n2. **Quantum cryptography**: Quantum systems can enable secure communication over long distances.\n3. **Quantum cosmology**: Quantum mechanics has implications for our understanding of the early universe and the origin of space-time.\n\n**Challenges and open questions:**\n\n1. **Interpretation of quantum mechanics**: There's ongoing debate about the fundamental nature of reality and how to interpret the mathematical formalism of quantum mechanics.\n2. **Quantum gravity**: The integration of quantum mechanics and general relativity is an active area of research.\n3. **Scalability**: Quantum systems are often fragile and difficult to scale up, making it challenging to build practical devices.\n\nThis is just a brief introduction to quantum mechanics. If you have specific questions or topics you'd like to explore further, feel free to ask!"}, {'role': 'user', 'content': 'wow. are you able to solve complex integrals?'}, {'role': 'assistant', 'content': "Yes, I'm capable of solving complex integrals, but with some limitations. I can:\n\n1. **Symbolically integrate**: I can use techniques like integration by parts, substitution, and integration by partial fractions to solve simple to moderately complex integrals.\n2. **Use numerical methods**: I can use numerical integration methods like Simpson's rule, trapezoidal rule, and Gaussian quadrature to approximate the value of an integral.\n3. **Apply special functions**: I'm familiar with special functions like gamma function, beta function, and error function, which can be used to simplify certain integrals.\n\nHowever, I'm not a replacement for a professional mathematician or a dedicated computer algebra system (CAS). I can struggle with:\n\n1. **Highly complex integrals**: Integrals that involve multiple nested integrals, fractional orders, or highly nonlinear functions can be challenging for me.\n2. **Non-standard notation**: If the integral is written in an unconventional or non-standard notation, I may have difficulty understanding it.\n3. **Advanced mathematical techniques**: Techniques like contour integration, residue calculus, or advanced differential equations may require more specialized knowledge than I possess.\n\nFeel free to provide an integral you'd like me to solve, and I'll do my best to help you."}, {'role': 'user', 'content': 'how can i import images for you?'}, {'role': 'assistant', 'content': "As a text-based AI model, I don't have direct access to your computer or the internet. However, you can use a few workarounds to share images with me:\n\n1. **Image URLs**: You can share the URL of an online image, and I can access it.\n2. **Image descriptions**: Describe the image using text, and I'll try my best to understand the context.\n3. **Upload images to a hosting platform**: You can upload the image to a hosting platform like imgur.com, dropbox.com, or google.com (Google Drive) and share the URL with me.\n\nKeep in mind that I won't be able to visually see the image, but I can try to understand the context based on the description or the URL.\n\n**If you need to ask me questions about the image:**\n\n1. **Describe the image**: Provide a detailed description of the image, including colors, shapes, objects, and any notable features.\n2. **Highlight specific areas**: Mention any specific areas or details in the image that you'd like me to focus on.\n\n**If you need to use the image for tasks:**\n\n1. **Convert the image to text**: If you have an image with text, you can use OCR (Optical Character Recognition) tools to convert the text into a readable format.\n2. **Use image processing software**: If you need to perform tasks like image segmentation, object detection, or image classification, you can use specialized software like Google Cloud Vision, Amazon Rekognition, or OpenCV.\n\nLet me know if there's anything else I can help with!"}, {'role': 'user', 'content': 'are there any limitations to waht i ask? nothing illegal ofcourse'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:09:52,610 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:09:52,610 [DEBUG] close.started
2026-02-24 13:09:52,610 [DEBUG] close.complete
2026-02-24 13:09:52,610 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:09:52,636 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F24003640>
2026-02-24 13:09:52,636 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023F235F4040> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:09:52,642 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F24003760>
2026-02-24 13:09:52,642 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:09:52,642 [DEBUG] send_request_headers.complete
2026-02-24 13:09:52,642 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:09:52,642 [DEBUG] send_request_body.complete
2026-02-24 13:09:52,642 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:09:52,739 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 07:39:52 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'4665'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'13.35s'), (b'x-request-id', b'req_01kj79e5wwe0fahqy6300221he'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2d4fc5bcb11b55-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:09:52,739 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:09:52,739 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 07:39:52 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '4665', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '13.35s', 'x-request-id': 'req_01kj79e5wwe0fahqy6300221he', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2d4fc5bcb11b55-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:09:52,739 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:09:53,556 [DEBUG] receive_response_body.complete
2026-02-24 13:09:53,556 [DEBUG] response_closed.started
2026-02-24 13:09:53,556 [DEBUG] response_closed.complete
2026-02-24 13:10:16,788 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-61ff2ffc-5035-4444-967a-d89e388ff7c0', 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}, {'role': 'assistant', 'content': "I'm functioning properly. What can I help you with today?"}, {'role': 'user', 'content': 'whatmodel are you?'}, {'role': 'assistant', 'content': "I'm an AI model developed by Meta AI. I'm a type of large language model, specifically a transformer-based model. My architecture is based on the BERT (Bidirectional Encoder Representations from Transformers) model."}, {'role': 'user', 'content': 'whats your name?'}, {'role': 'assistant', 'content': 'I don\'t have a personal name, but I\'m often referred to as Llama. Llama stands for "Large Language Model Meta AI."'}, {'role': 'user', 'content': 'tell me about quantum mechanics'}, {'role': 'assistant', 'content': "Quantum mechanics is a branch of physics that studies the behavior of matter and energy at an atomic and subatomic level. It's a fundamental aspect of the physical world that has been extensively studied and experimented with. Here's an overview:\n\n**Key principles:**\n\n1. **Wave-particle duality**: Quantum objects, such as electrons, can exhibit both wave-like and particle-like behavior depending on how they're observed.\n2. **Uncertainty principle**: It's impossible to know certain properties of a quantum system, like position and momentum, simultaneously with infinite precision.\n3. **Superposition**: Quantum objects can exist in multiple states simultaneously.\n4. **Entanglement**: Quantum objects can become connected in a way that their properties are correlated, even when separated by large distances.\n5. **Probabilistic nature**: Quantum mechanics is based on probabilities rather than definite outcomes.\n\n**Theories and models:**\n\n1. **Schrdinger equation**: A mathematical equation that describes the time-evolution of a quantum system.\n2. **Dirac equation**: A quantum equation that describes the behavior of fermions (particles with half-integer spin).\n3. **Quantum field theory**: A framework for describing the behavior of fundamental particles and forces in terms of fields that permeate space.\n\n**Experimental evidence:**\n\n1. **Double-slit experiment**: A classic experiment that demonstrated the wave-like behavior of electrons.\n2. **Quantum Eraser experiment**: A variation of the double-slit experiment that shows the effects of entanglement.\n3. **Quantum computing and cryptography**: Experiments that have demonstrated the potential of quantum computing and the security of quantum encryption.\n\n**Implications:**\n\n1. **Quantum computing**: Quantum systems can potentially solve certain problems much faster than classical computers.\n2. **Quantum cryptography**: Quantum systems can enable secure communication over long distances.\n3. **Quantum cosmology**: Quantum mechanics has implications for our understanding of the early universe and the origin of space-time.\n\n**Challenges and open questions:**\n\n1. **Interpretation of quantum mechanics**: There's ongoing debate about the fundamental nature of reality and how to interpret the mathematical formalism of quantum mechanics.\n2. **Quantum gravity**: The integration of quantum mechanics and general relativity is an active area of research.\n3. **Scalability**: Quantum systems are often fragile and difficult to scale up, making it challenging to build practical devices.\n\nThis is just a brief introduction to quantum mechanics. If you have specific questions or topics you'd like to explore further, feel free to ask!"}, {'role': 'user', 'content': 'wow. are you able to solve complex integrals?'}, {'role': 'assistant', 'content': "Yes, I'm capable of solving complex integrals, but with some limitations. I can:\n\n1. **Symbolically integrate**: I can use techniques like integration by parts, substitution, and integration by partial fractions to solve simple to moderately complex integrals.\n2. **Use numerical methods**: I can use numerical integration methods like Simpson's rule, trapezoidal rule, and Gaussian quadrature to approximate the value of an integral.\n3. **Apply special functions**: I'm familiar with special functions like gamma function, beta function, and error function, which can be used to simplify certain integrals.\n\nHowever, I'm not a replacement for a professional mathematician or a dedicated computer algebra system (CAS). I can struggle with:\n\n1. **Highly complex integrals**: Integrals that involve multiple nested integrals, fractional orders, or highly nonlinear functions can be challenging for me.\n2. **Non-standard notation**: If the integral is written in an unconventional or non-standard notation, I may have difficulty understanding it.\n3. **Advanced mathematical techniques**: Techniques like contour integration, residue calculus, or advanced differential equations may require more specialized knowledge than I possess.\n\nFeel free to provide an integral you'd like me to solve, and I'll do my best to help you."}, {'role': 'user', 'content': 'how can i import images for you?'}, {'role': 'assistant', 'content': "As a text-based AI model, I don't have direct access to your computer or the internet. However, you can use a few workarounds to share images with me:\n\n1. **Image URLs**: You can share the URL of an online image, and I can access it.\n2. **Image descriptions**: Describe the image using text, and I'll try my best to understand the context.\n3. **Upload images to a hosting platform**: You can upload the image to a hosting platform like imgur.com, dropbox.com, or google.com (Google Drive) and share the URL with me.\n\nKeep in mind that I won't be able to visually see the image, but I can try to understand the context based on the description or the URL.\n\n**If you need to ask me questions about the image:**\n\n1. **Describe the image**: Provide a detailed description of the image, including colors, shapes, objects, and any notable features.\n2. **Highlight specific areas**: Mention any specific areas or details in the image that you'd like me to focus on.\n\n**If you need to use the image for tasks:**\n\n1. **Convert the image to text**: If you have an image with text, you can use OCR (Optical Character Recognition) tools to convert the text into a readable format.\n2. **Use image processing software**: If you need to perform tasks like image segmentation, object detection, or image classification, you can use specialized software like Google Cloud Vision, Amazon Rekognition, or OpenCV.\n\nLet me know if there's anything else I can help with!"}, {'role': 'user', 'content': 'are there any limitations to waht i ask? nothing illegal ofcourse'}, {'role': 'assistant', 'content': "While I'm designed to be open and helpful, there are some limitations to what I can assist with:\n\n1. **SARCASM**: I'm not great at detecting sarcasm, and I might take it literally. Be clear and direct with your questions.\n2. **IDIOMS**: Idioms, colloquialisms, and figurative language can be challenging for me to understand.\n3. **ABSTRACT CONCEPTS**: While I can discuss complex topics, I might struggle with highly abstract or philosophical concepts that require a deep understanding of human thought and experience.\n4. **MATHEMATICAL PROOF**: I can assist with mathematical calculations, but proving complex theorems or deriving novel mathematical insights might be beyond my capabilities.\n5. **HIGHLY SPECIALIZED KNOWLEDGE**: I have a broad knowledge base, but I might not have in-depth expertise in extremely specialized subjects, such as cutting-edge research areas or highly niche topics.\n6. **REAL-TIME PROCESSING**: I'm not designed for real-time processing or decision-making. I can provide general guidance, but you should always verify information and consult with experts when necessary.\n7. **MULTIMEDIA CONTENT**: While I can handle text-based input, I'm not equipped to process or analyze multimedia content like audio, video, or images (except for describing them using text).\n8. **PERSONAL OPINIONS**: I don't have personal opinions or biases. My responses are based on patterns in the data I've been trained on, so keep in mind that I might not always agree with your views.\n9. **MULTIPLE TOPICS AT ONCE**: I can handle multiple topics, but if you ask too many questions at once, it might become difficult for me to provide clear and accurate responses.\n10. **DOMAIN-SPECIFIC REGULATIONS**: I'm not aware of specific domain-specific regulations or laws that might restrict certain types of conversations.\n\n**Keep in mind that:**\n\n* I'm designed to provide helpful and informative responses, but I'm not a substitute for professional advice, consulting expertise, or human judgment.\n* If you're unsure about the accuracy or relevance of my responses, feel free to ask for clarification or additional information.\n* I'll do my best to steer conversations towards safe, respectful, and informative topics.\n\nNow, what's on your mind?"}, {'role': 'user', 'content': ''}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:10:16,788 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:10:16,788 [DEBUG] close.started
2026-02-24 13:10:16,790 [DEBUG] close.complete
2026-02-24 13:10:16,790 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:10:16,806 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F2400CD60>
2026-02-24 13:10:16,806 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023F235F4040> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:10:16,820 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F2400CE20>
2026-02-24 13:10:16,821 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:10:16,821 [DEBUG] send_request_headers.complete
2026-02-24 13:10:16,821 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:10:16,821 [DEBUG] send_request_body.complete
2026-02-24 13:10:16,821 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:10:16,913 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 07:40:16 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'4181'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'18.189s'), (b'x-request-id', b'req_01kj79exg9e28s2y7tnf0pc937'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2d505cc913550c-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:10:16,913 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:10:16,913 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 07:40:16 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '4181', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '18.189s', 'x-request-id': 'req_01kj79exg9e28s2y7tnf0pc937', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2d505cc913550c-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:10:16,913 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:10:17,070 [DEBUG] receive_response_body.complete
2026-02-24 13:10:17,070 [DEBUG] response_closed.started
2026-02-24 13:10:17,070 [DEBUG] response_closed.complete
2026-02-24 13:10:59,789 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fb897ea9-4aef-4d05-8529-81ce23742f96', 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}, {'role': 'assistant', 'content': "I'm functioning properly. What can I help you with today?"}, {'role': 'user', 'content': 'whatmodel are you?'}, {'role': 'assistant', 'content': "I'm an AI model developed by Meta AI. I'm a type of large language model, specifically a transformer-based model. My architecture is based on the BERT (Bidirectional Encoder Representations from Transformers) model."}, {'role': 'user', 'content': 'whats your name?'}, {'role': 'assistant', 'content': 'I don\'t have a personal name, but I\'m often referred to as Llama. Llama stands for "Large Language Model Meta AI."'}, {'role': 'user', 'content': 'tell me about quantum mechanics'}, {'role': 'assistant', 'content': "Quantum mechanics is a branch of physics that studies the behavior of matter and energy at an atomic and subatomic level. It's a fundamental aspect of the physical world that has been extensively studied and experimented with. Here's an overview:\n\n**Key principles:**\n\n1. **Wave-particle duality**: Quantum objects, such as electrons, can exhibit both wave-like and particle-like behavior depending on how they're observed.\n2. **Uncertainty principle**: It's impossible to know certain properties of a quantum system, like position and momentum, simultaneously with infinite precision.\n3. **Superposition**: Quantum objects can exist in multiple states simultaneously.\n4. **Entanglement**: Quantum objects can become connected in a way that their properties are correlated, even when separated by large distances.\n5. **Probabilistic nature**: Quantum mechanics is based on probabilities rather than definite outcomes.\n\n**Theories and models:**\n\n1. **Schrdinger equation**: A mathematical equation that describes the time-evolution of a quantum system.\n2. **Dirac equation**: A quantum equation that describes the behavior of fermions (particles with half-integer spin).\n3. **Quantum field theory**: A framework for describing the behavior of fundamental particles and forces in terms of fields that permeate space.\n\n**Experimental evidence:**\n\n1. **Double-slit experiment**: A classic experiment that demonstrated the wave-like behavior of electrons.\n2. **Quantum Eraser experiment**: A variation of the double-slit experiment that shows the effects of entanglement.\n3. **Quantum computing and cryptography**: Experiments that have demonstrated the potential of quantum computing and the security of quantum encryption.\n\n**Implications:**\n\n1. **Quantum computing**: Quantum systems can potentially solve certain problems much faster than classical computers.\n2. **Quantum cryptography**: Quantum systems can enable secure communication over long distances.\n3. **Quantum cosmology**: Quantum mechanics has implications for our understanding of the early universe and the origin of space-time.\n\n**Challenges and open questions:**\n\n1. **Interpretation of quantum mechanics**: There's ongoing debate about the fundamental nature of reality and how to interpret the mathematical formalism of quantum mechanics.\n2. **Quantum gravity**: The integration of quantum mechanics and general relativity is an active area of research.\n3. **Scalability**: Quantum systems are often fragile and difficult to scale up, making it challenging to build practical devices.\n\nThis is just a brief introduction to quantum mechanics. If you have specific questions or topics you'd like to explore further, feel free to ask!"}, {'role': 'user', 'content': 'wow. are you able to solve complex integrals?'}, {'role': 'assistant', 'content': "Yes, I'm capable of solving complex integrals, but with some limitations. I can:\n\n1. **Symbolically integrate**: I can use techniques like integration by parts, substitution, and integration by partial fractions to solve simple to moderately complex integrals.\n2. **Use numerical methods**: I can use numerical integration methods like Simpson's rule, trapezoidal rule, and Gaussian quadrature to approximate the value of an integral.\n3. **Apply special functions**: I'm familiar with special functions like gamma function, beta function, and error function, which can be used to simplify certain integrals.\n\nHowever, I'm not a replacement for a professional mathematician or a dedicated computer algebra system (CAS). I can struggle with:\n\n1. **Highly complex integrals**: Integrals that involve multiple nested integrals, fractional orders, or highly nonlinear functions can be challenging for me.\n2. **Non-standard notation**: If the integral is written in an unconventional or non-standard notation, I may have difficulty understanding it.\n3. **Advanced mathematical techniques**: Techniques like contour integration, residue calculus, or advanced differential equations may require more specialized knowledge than I possess.\n\nFeel free to provide an integral you'd like me to solve, and I'll do my best to help you."}, {'role': 'user', 'content': 'how can i import images for you?'}, {'role': 'assistant', 'content': "As a text-based AI model, I don't have direct access to your computer or the internet. However, you can use a few workarounds to share images with me:\n\n1. **Image URLs**: You can share the URL of an online image, and I can access it.\n2. **Image descriptions**: Describe the image using text, and I'll try my best to understand the context.\n3. **Upload images to a hosting platform**: You can upload the image to a hosting platform like imgur.com, dropbox.com, or google.com (Google Drive) and share the URL with me.\n\nKeep in mind that I won't be able to visually see the image, but I can try to understand the context based on the description or the URL.\n\n**If you need to ask me questions about the image:**\n\n1. **Describe the image**: Provide a detailed description of the image, including colors, shapes, objects, and any notable features.\n2. **Highlight specific areas**: Mention any specific areas or details in the image that you'd like me to focus on.\n\n**If you need to use the image for tasks:**\n\n1. **Convert the image to text**: If you have an image with text, you can use OCR (Optical Character Recognition) tools to convert the text into a readable format.\n2. **Use image processing software**: If you need to perform tasks like image segmentation, object detection, or image classification, you can use specialized software like Google Cloud Vision, Amazon Rekognition, or OpenCV.\n\nLet me know if there's anything else I can help with!"}, {'role': 'user', 'content': 'are there any limitations to waht i ask? nothing illegal ofcourse'}, {'role': 'assistant', 'content': "While I'm designed to be open and helpful, there are some limitations to what I can assist with:\n\n1. **SARCASM**: I'm not great at detecting sarcasm, and I might take it literally. Be clear and direct with your questions.\n2. **IDIOMS**: Idioms, colloquialisms, and figurative language can be challenging for me to understand.\n3. **ABSTRACT CONCEPTS**: While I can discuss complex topics, I might struggle with highly abstract or philosophical concepts that require a deep understanding of human thought and experience.\n4. **MATHEMATICAL PROOF**: I can assist with mathematical calculations, but proving complex theorems or deriving novel mathematical insights might be beyond my capabilities.\n5. **HIGHLY SPECIALIZED KNOWLEDGE**: I have a broad knowledge base, but I might not have in-depth expertise in extremely specialized subjects, such as cutting-edge research areas or highly niche topics.\n6. **REAL-TIME PROCESSING**: I'm not designed for real-time processing or decision-making. I can provide general guidance, but you should always verify information and consult with experts when necessary.\n7. **MULTIMEDIA CONTENT**: While I can handle text-based input, I'm not equipped to process or analyze multimedia content like audio, video, or images (except for describing them using text).\n8. **PERSONAL OPINIONS**: I don't have personal opinions or biases. My responses are based on patterns in the data I've been trained on, so keep in mind that I might not always agree with your views.\n9. **MULTIPLE TOPICS AT ONCE**: I can handle multiple topics, but if you ask too many questions at once, it might become difficult for me to provide clear and accurate responses.\n10. **DOMAIN-SPECIFIC REGULATIONS**: I'm not aware of specific domain-specific regulations or laws that might restrict certain types of conversations.\n\n**Keep in mind that:**\n\n* I'm designed to provide helpful and informative responses, but I'm not a substitute for professional advice, consulting expertise, or human judgment.\n* If you're unsure about the accuracy or relevance of my responses, feel free to ask for clarification or additional information.\n* I'll do my best to steer conversations towards safe, respectful, and informative topics.\n\nNow, what's on your mind?"}, {'role': 'user', 'content': ''}, {'role': 'assistant', 'content': "It seems like you stopped typing. If you have a question or topic you'd like to discuss, feel free to share it with me now!"}, {'role': 'user', 'content': 'byebye'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:10:59,789 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:10:59,789 [DEBUG] close.started
2026-02-24 13:10:59,789 [DEBUG] close.complete
2026-02-24 13:10:59,789 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:10:59,839 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F2400E4A0>
2026-02-24 13:10:59,839 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023F235F4040> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:10:59,851 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023F2400E500>
2026-02-24 13:10:59,851 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:10:59,851 [DEBUG] send_request_headers.complete
2026-02-24 13:10:59,851 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:10:59,853 [DEBUG] send_request_body.complete
2026-02-24 13:10:59,853 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:10:59,952 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 07:40:59 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'4140'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'18.6s'), (b'x-request-id', b'req_01kj79g7h0eafbgekwtr9733tv'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2d5169bc638e7b-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:10:59,952 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:10:59,952 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 07:40:59 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '4140', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '18.6s', 'x-request-id': 'req_01kj79g7h0eafbgekwtr9733tv', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2d5169bc638e7b-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:10:59,952 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:11:00,124 [DEBUG] receive_response_body.complete
2026-02-24 13:11:00,124 [DEBUG] response_closed.started
2026-02-24 13:11:00,124 [DEBUG] response_closed.complete
2026-02-24 13:11:04,855 [INFO] Boot Complete
2026-02-24 13:13:33,973 [INFO] Boot Seqeunce Started
2026-02-24 13:13:35,913 [INFO] Boot Complete
2026-02-24 13:21:57,509 [INFO] Boot Seqeunce Started
2026-02-24 13:22:04,774 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:22:11,164 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-20cd93bc-7cdf-44fe-b4be-21bddb3f1a9b', 'json_data': {'messages': [{'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello.'}, {'role': 'user', 'content': 'how are u'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:22:11,206 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:22:11,206 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:22:11,250 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023BE3181D50>
2026-02-24 13:22:11,250 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023BE2FCC340> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:22:11,264 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023BE3181BA0>
2026-02-24 13:22:11,264 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:22:11,265 [DEBUG] send_request_headers.complete
2026-02-24 13:22:11,265 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:22:11,265 [DEBUG] send_request_body.complete
2026-02-24 13:22:11,265 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:22:11,352 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 07:52:11 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5948'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'520ms'), (b'x-request-id', b'req_01kj7a4q64fkhsnzvq5azh8d5f'), (b'via', b'1.1 google'), (b'set-cookie', b'__cf_bm=pQ5kAV1LiVlW.o7CwAJDXbHqOM1rOWKXr0WIxmPXUzg-1771919531.1984165-1.0.1.1-V6Vn9m8QKDN6mZcFur6tZ2RJHkiue8XRgLW.UiVFnKgmaMnkdUBjqUbJ9D1Mw2I0x4Bred4UfUAXxavtQQ5juUz0W2av5LjJSdCjLDcpslbN_tUoIttrUSao2KBFthOf; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:22:11 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2d61cdf83ac27b-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:22:11,353 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:22:11,353 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 07:52:11 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5948', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '520ms', 'x-request-id': 'req_01kj7a4q64fkhsnzvq5azh8d5f', 'via': '1.1 google', 'set-cookie': '__cf_bm=pQ5kAV1LiVlW.o7CwAJDXbHqOM1rOWKXr0WIxmPXUzg-1771919531.1984165-1.0.1.1-V6Vn9m8QKDN6mZcFur6tZ2RJHkiue8XRgLW.UiVFnKgmaMnkdUBjqUbJ9D1Mw2I0x4Bred4UfUAXxavtQQ5juUz0W2av5LjJSdCjLDcpslbN_tUoIttrUSao2KBFthOf; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:22:11 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2d61cdf83ac27b-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:22:11,353 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:22:11,374 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:22:17,830 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:22:24,364 [DEBUG] receive_response_body.complete
2026-02-24 13:22:24,364 [DEBUG] response_closed.started
2026-02-24 13:22:24,364 [DEBUG] response_closed.complete
2026-02-24 13:22:29,790 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2ed9c60f-51f5-4e7e-b4f9-0146a7d17d53', 'json_data': {'messages': [{'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': 'Hello.'}, {'role': 'user', 'content': 'how are u'}, {'role': 'assistant', 'content': "I'm just a computer program, so I don't have feelings or emotions like humans do. I'm functioning properly and ready to help with any questions or tasks you may have."}, {'role': 'user', 'content': 'explain quantum mechanics like im 5'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:22:29,790 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:22:29,791 [DEBUG] close.started
2026-02-24 13:22:29,791 [DEBUG] close.complete
2026-02-24 13:22:29,791 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:22:29,810 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023BE3183F70>
2026-02-24 13:22:29,810 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023BE2FCC340> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:22:29,826 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023BE3183460>
2026-02-24 13:22:29,826 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:22:29,827 [DEBUG] send_request_headers.complete
2026-02-24 13:22:29,827 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:22:29,827 [DEBUG] send_request_body.complete
2026-02-24 13:22:29,827 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:22:29,921 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 07:52:29 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5895'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'1.05s'), (b'x-request-id', b'req_01kj7a59adfdnb01a1wdvwwkka'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2d62420fbd54a4-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:22:29,921 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:22:29,921 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 07:52:29 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5895', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '1.05s', 'x-request-id': 'req_01kj7a59adfdnb01a1wdvwwkka', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2d62420fbd54a4-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:22:29,922 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:22:29,934 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:22:35,295 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:22:44,133 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:22:53,382 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:23:00,210 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:23:03,893 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:23:14,590 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:23:18,580 [INFO] Boot Complete
2026-02-24 13:23:18,599 [DEBUG] receive_response_body.failed exception=GeneratorExit()
2026-02-24 13:23:18,600 [DEBUG] response_closed.started
2026-02-24 13:23:18,601 [DEBUG] response_closed.complete
2026-02-24 13:27:51,805 [INFO] Boot Seqeunce Started
2026-02-24 13:27:57,188 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-89b6d0ca-0c85-4354-8912-2ef994a9768f', 'json_data': {'messages': [{'role': 'user', 'content': 'explain quantum mechanics'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:27:57,587 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:27:57,587 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:27:57,644 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002896C009690>
2026-02-24 13:27:57,644 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000002896BE905C0> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:27:57,661 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002896C009720>
2026-02-24 13:27:57,661 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:27:57,662 [DEBUG] send_request_headers.complete
2026-02-24 13:27:57,662 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:27:57,662 [DEBUG] send_request_body.complete
2026-02-24 13:27:57,662 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:27:57,750 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 07:57:57 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5961'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'389ms'), (b'x-request-id', b'req_01kj7af9f0ecztdh72v86f4bs4'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'set-cookie', b'__cf_bm=Qnb1dAMvj0JLEVc_uMuWaeoFONlAQvodTXAig.zrauY-1771919877.5919068-1.0.1.1-COEvLjiSn6TjT_0oSqODUYluerdsNDgmKzWFAYGJ7k2Fk6O0IL34eVapsJE1xgdWlTm76GCFWEK2QZ8Bm5ofsMMwChzhWcFyXzr1uaVmcX.gKPXjOvfsGcgrXaCBwHTb; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:27:57 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2d6a42fa5854e0-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:27:57,751 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:27:57,751 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 07:57:57 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5961', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '389ms', 'x-request-id': 'req_01kj7af9f0ecztdh72v86f4bs4', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=Qnb1dAMvj0JLEVc_uMuWaeoFONlAQvodTXAig.zrauY-1771919877.5919068-1.0.1.1-COEvLjiSn6TjT_0oSqODUYluerdsNDgmKzWFAYGJ7k2Fk6O0IL34eVapsJE1xgdWlTm76GCFWEK2QZ8Bm5ofsMMwChzhWcFyXzr1uaVmcX.gKPXjOvfsGcgrXaCBwHTb; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:27:57 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2d6a42fa5854e0-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:27:57,752 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:27:57,787 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:27:58,701 [DEBUG] receive_response_body.complete
2026-02-24 13:27:58,701 [DEBUG] response_closed.started
2026-02-24 13:27:58,701 [DEBUG] response_closed.complete
2026-02-24 13:28:06,087 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:28:15,106 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:28:20,644 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:28:26,962 [INFO] Boot Complete
2026-02-24 13:42:57,632 [INFO] Boot Seqeunce Started
2026-02-24 13:43:10,130 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-45b28d77-5bb1-4d14-872e-4873f4284a6c', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain parallelogram law of vectors'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:43:10,179 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:43:10,179 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:43:10,227 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AAC3B89630>
2026-02-24 13:43:10,227 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AAC3A10540> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:43:10,243 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AAC3B896C0>
2026-02-24 13:43:10,243 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:43:10,243 [DEBUG] send_request_headers.complete
2026-02-24 13:43:10,243 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:43:10,243 [DEBUG] send_request_body.complete
2026-02-24 13:43:10,243 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:43:10,340 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 08:13:10 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5920'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'800ms'), (b'x-request-id', b'req_01kj7bb4n1fpw96m92dystwa9n'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'set-cookie', b'__cf_bm=yGZswVyabKjgEeV8r5IBuj4VLUNbgzc_bjyoJXu0BgU-1771920790.1694198-1.0.1.1-ABKI7o.215mNYXpf0FJzxxWA_qAXbaoe3YLk646IO6qBS40A_0xj_mUdmjnbJBHWzoHcrQOPcV23c8E15w.eYoMzVCX5J6YYsmKPIjCGm9UtUBGvYsCqOnMGJyGoKWyd; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:43:10 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2d808a8bb2548c-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:43:10,340 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:43:10,340 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 08:13:10 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5920', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '800ms', 'x-request-id': 'req_01kj7bb4n1fpw96m92dystwa9n', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=yGZswVyabKjgEeV8r5IBuj4VLUNbgzc_bjyoJXu0BgU-1771920790.1694198-1.0.1.1-ABKI7o.215mNYXpf0FJzxxWA_qAXbaoe3YLk646IO6qBS40A_0xj_mUdmjnbJBHWzoHcrQOPcV23c8E15w.eYoMzVCX5J6YYsmKPIjCGm9UtUBGvYsCqOnMGJyGoKWyd; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:43:10 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2d808a8bb2548c-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:43:10,340 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:43:10,370 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:43:10,534 [DEBUG] receive_response_body.complete
2026-02-24 13:43:10,535 [DEBUG] response_closed.started
2026-02-24 13:43:10,535 [DEBUG] response_closed.complete
2026-02-24 13:43:15,524 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:43:18,969 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:43:22,708 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:43:26,679 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:43:30,639 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:43:32,886 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:43:36,750 [INFO] Boot Complete
2026-02-24 13:46:39,534 [INFO] Boot Seqeunce Started
2026-02-24 13:46:50,220 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-eaeaa916-37c6-4b72-a7e2-d77f5d6cfef4', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain gravity in simple terms'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:46:50,259 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:46:50,259 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:46:50,298 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F0664F96C0>
2026-02-24 13:46:50,298 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F066380540> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:46:50,322 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F0664F9750>
2026-02-24 13:46:50,322 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:46:50,322 [DEBUG] send_request_headers.complete
2026-02-24 13:46:50,322 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:46:50,322 [DEBUG] send_request_body.complete
2026-02-24 13:46:50,322 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:46:50,396 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 08:16:50 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5922'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'779ms'), (b'x-request-id', b'req_01kj7bhvhvemgbs3chgr5hrzpc'), (b'via', b'1.1 google'), (b'set-cookie', b'__cf_bm=I6EVpHhGEuyw3MnHAOYn3Jgzw5CzqzF3Vzg5EqmR8D0-1771921010.231041-1.0.1.1-IOc_da3uCjb2SL_Y6IfcnjDGFydLu6YSsu7C7Sk2lSL5fyYLmKU69uF.nHOfupAA5czoL1YwAdxza33zuNWiNHbR2WDsKINuJTxcYoKh3K.NvU6lLdT463uXheOnjkel; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:46:50 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2d85e9ff5f4723-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:46:50,396 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:46:50,396 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 08:16:50 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5922', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '779ms', 'x-request-id': 'req_01kj7bhvhvemgbs3chgr5hrzpc', 'via': '1.1 google', 'set-cookie': '__cf_bm=I6EVpHhGEuyw3MnHAOYn3Jgzw5CzqzF3Vzg5EqmR8D0-1771921010.231041-1.0.1.1-IOc_da3uCjb2SL_Y6IfcnjDGFydLu6YSsu7C7Sk2lSL5fyYLmKU69uF.nHOfupAA5czoL1YwAdxza33zuNWiNHbR2WDsKINuJTxcYoKh3K.NvU6lLdT463uXheOnjkel; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:46:50 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2d85e9ff5f4723-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:46:50,396 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:46:50,420 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:46:50,510 [DEBUG] receive_response_body.complete
2026-02-24 13:46:50,510 [DEBUG] response_closed.started
2026-02-24 13:46:50,510 [DEBUG] response_closed.complete
2026-02-24 13:46:52,990 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:46:56,748 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:46:59,666 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:47:02,442 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:47:06,230 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:47:09,567 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:47:12,704 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:47:43,198 [INFO] Boot Complete
2026-02-24 13:50:03,896 [INFO] Boot Seqeunce Started
2026-02-24 13:50:08,308 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-86c011bc-deb0-4eb4-9e8a-956b44da4e7a', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:50:08,348 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:50:08,348 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:50:08,397 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EAC58896F0>
2026-02-24 13:50:08,397 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EAC5710540> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:50:08,413 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EAC5889780>
2026-02-24 13:50:08,413 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:50:08,413 [DEBUG] send_request_headers.complete
2026-02-24 13:50:08,413 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:50:08,413 [DEBUG] send_request_body.complete
2026-02-24 13:50:08,413 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:50:08,505 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 08:20:08 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5925'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'750ms'), (b'x-request-id', b'req_01kj7bqx0df19ashn4360w4j8w'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'set-cookie', b'__cf_bm=3I7Xs.pn793GySCRexAx2KyR.rFS0rYniqFwSAgM2Ao-1771921208.3249297-1.0.1.1-G1xtc_5LD9hSXm8KsoxOZP9kCSMUdrvAsa0kKedHZKq4XMCyQXBkeey4PUIDc2MQdbHiVt6vXh6Hut6xNLoif228d5aiULxfkQHzirbF2Hi7fN81bUAj7PokNEFoqhlT; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:50:08 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2d8ac00ae25472-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:50:08,507 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:50:08,507 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 08:20:08 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5925', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '750ms', 'x-request-id': 'req_01kj7bqx0df19ashn4360w4j8w', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=3I7Xs.pn793GySCRexAx2KyR.rFS0rYniqFwSAgM2Ao-1771921208.3249297-1.0.1.1-G1xtc_5LD9hSXm8KsoxOZP9kCSMUdrvAsa0kKedHZKq4XMCyQXBkeey4PUIDc2MQdbHiVt6vXh6Hut6xNLoif228d5aiULxfkQHzirbF2Hi7fN81bUAj7PokNEFoqhlT; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:50:08 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2d8ac00ae25472-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:50:08,507 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:50:08,535 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:50:08,659 [DEBUG] receive_response_body.complete
2026-02-24 13:50:08,659 [DEBUG] response_closed.started
2026-02-24 13:50:08,659 [DEBUG] response_closed.complete
2026-02-24 13:50:21,910 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-26a8189a-6654-4ea9-b801-2619598d151f', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain gravity'}, {'role': 'assistant', 'content': '**Gravity**: \nGravity is a universal force that attracts two objects with mass towards each other. \n\n**Key Aspects**:\n\n1. **Mass**: The more massive the objects, the stronger the gravitational pull.\n2. **Distance**: Gravity weakens with increased distance between objects.\n3. **Warped Space-Time**: Gravity warps the fabric of space-time around massive objects.\n\n**Theorized by Albert Einstein**, the General Theory of Relativity explains gravity as the curvature of space-time by massive objects.'}, {'role': 'user', 'content': 'clear'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:50:21,910 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:50:21,910 [DEBUG] close.started
2026-02-24 13:50:21,910 [DEBUG] close.complete
2026-02-24 13:50:21,910 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:50:21,931 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EAC588AC20>
2026-02-24 13:50:21,931 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EAC5710540> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:50:21,931 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EAC588ACE0>
2026-02-24 13:50:21,931 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:50:21,945 [DEBUG] send_request_headers.complete
2026-02-24 13:50:21,945 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:50:21,945 [DEBUG] send_request_body.complete
2026-02-24 13:50:21,946 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:50:22,029 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 08:20:21 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5811'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'1.89s'), (b'x-request-id', b'req_01kj7bra78f24931ghvp3x1v1q'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2d8b149dbf5492-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:50:22,029 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:50:22,029 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 08:20:21 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5811', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '1.89s', 'x-request-id': 'req_01kj7bra78f24931ghvp3x1v1q', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2d8b149dbf5492-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:50:22,029 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:50:22,150 [DEBUG] receive_response_body.complete
2026-02-24 13:50:22,162 [DEBUG] response_closed.started
2026-02-24 13:50:22,162 [DEBUG] response_closed.complete
2026-02-24 13:50:24,462 [INFO] Boot Complete
2026-02-24 13:50:39,166 [INFO] Boot Seqeunce Started
2026-02-24 13:50:42,099 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-6ded7f7f-fdaf-4f71-b539-47fc2a8b4bab', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:50:42,149 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:50:42,149 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:50:42,182 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9A8729720>
2026-02-24 13:50:42,182 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C9A85B0540> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:50:42,198 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9A87297B0>
2026-02-24 13:50:42,198 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:50:42,198 [DEBUG] send_request_headers.complete
2026-02-24 13:50:42,198 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:50:42,198 [DEBUG] send_request_body.complete
2026-02-24 13:50:42,198 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:50:42,281 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 08:20:42 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5925'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'750ms'), (b'x-request-id', b'req_01kj7brxzyeg78g50vc1xjk0rf'), (b'via', b'1.1 google'), (b'set-cookie', b'__cf_bm=nlMG5mXuykKcpFt2gDieS8uxYFcU2bLSEz6Hh0l4sc4-1771921242.1016142-1.0.1.1-WdaM1iGQc7Ji99UKe5EU0tAA_Opw9MNC494kQ2tC9K_UexkHC.3SA_SjgNW.6Cp9G4v_rXHUBSd7kFiiyCVflNpA3jotg0wbsFF0_OW4qXYFzEGr5uFqU8Me1QEU03sP; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:50:42 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2d8b932d745981-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:50:42,281 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:50:42,281 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 08:20:42 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5925', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '750ms', 'x-request-id': 'req_01kj7brxzyeg78g50vc1xjk0rf', 'via': '1.1 google', 'set-cookie': '__cf_bm=nlMG5mXuykKcpFt2gDieS8uxYFcU2bLSEz6Hh0l4sc4-1771921242.1016142-1.0.1.1-WdaM1iGQc7Ji99UKe5EU0tAA_Opw9MNC494kQ2tC9K_UexkHC.3SA_SjgNW.6Cp9G4v_rXHUBSd7kFiiyCVflNpA3jotg0wbsFF0_OW4qXYFzEGr5uFqU8Me1QEU03sP; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:50:42 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2d8b932d745981-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:50:42,281 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:50:42,297 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:50:42,516 [DEBUG] receive_response_body.complete
2026-02-24 13:50:42,516 [DEBUG] response_closed.started
2026-02-24 13:50:42,516 [DEBUG] response_closed.complete
2026-02-24 13:50:48,534 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:50:53,304 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:50:57,540 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:51:02,866 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:51:05,189 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:51:11,132 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:51:13,602 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:51:16,726 [INFO] Boot Complete
2026-02-24 13:55:59,346 [INFO] Boot Seqeunce Started
2026-02-24 13:56:04,056 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-dd4d606b-54df-4182-a810-50524035f1e8', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:56:04,100 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:56:04,100 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:56:04,137 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016BFF704820>
2026-02-24 13:56:04,137 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000016BFF584440> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:56:04,137 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016BFF7048B0>
2026-02-24 13:56:04,137 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:56:04,137 [DEBUG] send_request_headers.complete
2026-02-24 13:56:04,137 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:56:04,137 [DEBUG] send_request_body.complete
2026-02-24 13:56:04,137 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:56:04,234 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 08:26:04 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5925'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'750ms'), (b'x-request-id', b'req_01kj7c2rcsfrwa426pd2279jm8'), (b'via', b'1.1 google'), (b'set-cookie', b'__cf_bm=KWV09aIzxM.MdI_D8ubB82OA21dK0hnqiNbxuydxuaE-1771921564.0522137-1.0.1.1-ETEtia59PyAtoa8feM3CQpJ4hUqXrV505If5auKayfVqim8Z20HSqP2huc9Vy5uZOXFMTwAA6zQGYLrcICoIjHIr1XEGsIc3aEA6SZ1UFUj0TiA780iOr9swqjBEwn70; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:56:04 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2d936f5c80dfdc-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:56:04,234 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:56:04,234 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 08:26:04 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5925', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '750ms', 'x-request-id': 'req_01kj7c2rcsfrwa426pd2279jm8', 'via': '1.1 google', 'set-cookie': '__cf_bm=KWV09aIzxM.MdI_D8ubB82OA21dK0hnqiNbxuydxuaE-1771921564.0522137-1.0.1.1-ETEtia59PyAtoa8feM3CQpJ4hUqXrV505If5auKayfVqim8Z20HSqP2huc9Vy5uZOXFMTwAA6zQGYLrcICoIjHIr1XEGsIc3aEA6SZ1UFUj0TiA780iOr9swqjBEwn70; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 08:56:04 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2d936f5c80dfdc-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:56:04,234 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:56:04,276 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:56:04,473 [DEBUG] receive_response_body.complete
2026-02-24 13:56:04,473 [DEBUG] response_closed.started
2026-02-24 13:56:04,473 [DEBUG] response_closed.complete
2026-02-24 13:56:10,841 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:56:15,581 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:56:21,199 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:56:33,791 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:56:41,666 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:56:46,681 [DEBUG] Using proactor: IocpProactor
2026-02-24 13:56:54,377 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-5c2b403a-3093-4a08-8157-58a95124e906', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain gravity'}, {'role': 'assistant', 'content': "**Gravity:** \nGravity is a fundamental force of nature. It's the attraction between two objects with mass. The more massive the objects, the stronger the gravitational pull.\n\n**Theories:**\n\n- **Newton's Law of Universal Gravitation:** Describes gravity as a force acting between objects, proportional to their mass and the distance between them.\n- **General Relativity (Einstein):** Describes gravity as the curvature of spacetime caused by massive objects. Objects move along curved paths due to this curvature.\n\n**Key Effects of Gravity:**\n\n- Attraction of objects towards each other\n- Orbital motion (e.g., planets around stars)\n- Falling or weight on objects"}, {'role': 'user', 'content': 'helo'}, {'role': 'assistant', 'content': 'Hello.'}, {'role': 'user', 'content': 'speek'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 13:56:54,377 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 13:56:54,377 [DEBUG] close.started
2026-02-24 13:56:54,377 [DEBUG] close.complete
2026-02-24 13:56:54,377 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 13:56:54,388 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016BFF7A80A0>
2026-02-24 13:56:54,389 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000016BFF584440> server_hostname='api.groq.com' timeout=5.0
2026-02-24 13:56:54,399 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000016BFF7A8040>
2026-02-24 13:56:54,403 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 13:56:54,403 [DEBUG] send_request_headers.complete
2026-02-24 13:56:54,403 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 13:56:54,403 [DEBUG] send_request_body.complete
2026-02-24 13:56:54,403 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 13:56:54,487 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 08:26:54 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5761'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'2.389s'), (b'x-request-id', b'req_01kj7c49f5ffwshhj3j7t0fz9t'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2d94a96a078e78-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 13:56:54,488 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 13:56:54,488 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 08:26:54 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5761', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '2.389s', 'x-request-id': 'req_01kj7c49f5ffwshhj3j7t0fz9t', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2d94a96a078e78-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 13:56:54,488 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 13:56:54,511 [DEBUG] receive_response_body.complete
2026-02-24 13:56:54,511 [DEBUG] response_closed.started
2026-02-24 13:56:54,511 [DEBUG] response_closed.complete
2026-02-24 13:56:56,918 [DEBUG] Using proactor: IocpProactor
2026-02-24 14:12:04,573 [INFO] Boot Complete
2026-02-24 14:29:08,064 [INFO] Boot Seqeunce Started
2026-02-24 14:29:13,538 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d95aa957-d3b8-4a27-a0ae-b6ceac80b56d', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain quantum mechanics'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:29:13,582 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:29:13,582 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:29:13,614 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002036E686B30>
2026-02-24 14:29:13,614 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000002036E3EC540> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:29:13,620 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002036E686BC0>
2026-02-24 14:29:13,635 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:29:13,635 [DEBUG] send_request_headers.complete
2026-02-24 14:29:13,635 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:29:13,635 [DEBUG] send_request_body.complete
2026-02-24 14:29:13,635 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:29:13,731 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 08:59:13 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5924'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'760ms'), (b'x-request-id', b'req_01kj7dzf7hegct9ed8fpg294bs'), (b'via', b'1.1 google'), (b'set-cookie', b'__cf_bm=4APUZZMeIieQp5QSrCSuAbClTtuAjS_.7MO_UiUCIzg-1771923553.5159554-1.0.1.1-495xvKpvr0dLn8zvYDl70Yzj4BqilH.U3FFwBJSgSn7krFYaFXuCaAFOP_YRDDWpjQR0FwMX76Ox14bk.MNbaZwlCxw73ppasEXx1QHvkzuNDwvj.KCEJLjzwDAExajg; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:29:13 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2dc4017ec91b55-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:29:13,731 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:29:13,731 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 08:59:13 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5924', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '760ms', 'x-request-id': 'req_01kj7dzf7hegct9ed8fpg294bs', 'via': '1.1 google', 'set-cookie': '__cf_bm=4APUZZMeIieQp5QSrCSuAbClTtuAjS_.7MO_UiUCIzg-1771923553.5159554-1.0.1.1-495xvKpvr0dLn8zvYDl70Yzj4BqilH.U3FFwBJSgSn7krFYaFXuCaAFOP_YRDDWpjQR0FwMX76Ox14bk.MNbaZwlCxw73ppasEXx1QHvkzuNDwvj.KCEJLjzwDAExajg; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:29:13 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2dc4017ec91b55-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:29:13,731 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:29:14,239 [DEBUG] receive_response_body.complete
2026-02-24 14:29:14,239 [DEBUG] response_closed.started
2026-02-24 14:29:14,240 [DEBUG] response_closed.complete
2026-02-24 14:33:08,548 [INFO] Boot Complete
2026-02-24 14:33:11,579 [INFO] Boot Seqeunce Started
2026-02-24 14:33:15,958 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2e0526ed-a33d-439d-a760-2a0e2bc64bdf', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:33:16,008 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:33:16,008 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:33:16,056 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A5D0582A40>
2026-02-24 14:33:16,056 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A5D0278540> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:33:16,056 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A5D0582AD0>
2026-02-24 14:33:16,072 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:33:16,072 [DEBUG] send_request_headers.complete
2026-02-24 14:33:16,072 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:33:16,072 [DEBUG] send_request_body.complete
2026-02-24 14:33:16,072 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:33:16,160 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:03:16 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5925'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'750ms'), (b'x-request-id', b'req_01kj7e6vzqeyt8wpfc0gvvydxf'), (b'via', b'1.1 google'), (b'set-cookie', b'__cf_bm=iy71Rx7NzroBNB_Y_UHlIVvgohDyp6NUyFMLa3q8CLE-1771923795.9535136-1.0.1.1-zrmPGwgJMOnxiHl9F_pqhduLGxZvqswtEHz78DFv5PTFtLmsp0QhB7NcuhXSRvtV8ha9M_ypmsKl01yKnrW9bhdL84CHFyir6d2xaIVcBL4mYr1g66jzmZEnK3rzQJo2; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:33:16 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2dc9ecbcd24723-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:33:16,160 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:33:16,160 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:03:16 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5925', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '750ms', 'x-request-id': 'req_01kj7e6vzqeyt8wpfc0gvvydxf', 'via': '1.1 google', 'set-cookie': '__cf_bm=iy71Rx7NzroBNB_Y_UHlIVvgohDyp6NUyFMLa3q8CLE-1771923795.9535136-1.0.1.1-zrmPGwgJMOnxiHl9F_pqhduLGxZvqswtEHz78DFv5PTFtLmsp0QhB7NcuhXSRvtV8ha9M_ypmsKl01yKnrW9bhdL84CHFyir6d2xaIVcBL4mYr1g66jzmZEnK3rzQJo2; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:33:16 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2dc9ecbcd24723-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:33:16,160 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:33:16,348 [DEBUG] receive_response_body.complete
2026-02-24 14:33:16,349 [DEBUG] response_closed.started
2026-02-24 14:33:16,349 [DEBUG] response_closed.complete
2026-02-24 14:33:43,928 [INFO] Boot Complete
2026-02-24 14:37:41,056 [INFO] Boot Seqeunce Started
2026-02-24 14:37:44,680 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-69d6ae7b-80e0-47b9-b67b-cb226f2a497a', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:37:44,720 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:37:44,721 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:37:44,773 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000254D2F129E0>
2026-02-24 14:37:44,773 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x00000254D2410540> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:37:44,773 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000254D2F12A70>
2026-02-24 14:37:44,773 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:37:44,773 [DEBUG] send_request_headers.complete
2026-02-24 14:37:44,773 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:37:44,789 [DEBUG] send_request_body.complete
2026-02-24 14:37:44,789 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:37:44,870 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:07:44 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5925'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'750ms'), (b'x-request-id', b'req_01kj7ef2cqe01sw14ptgkd7gpj'), (b'via', b'1.1 google'), (b'set-cookie', b'__cf_bm=pJdhMDOkiSAxlisbv1iHQ673qcXiLSo_MS8k1aeXsHM-1771924064.6540754-1.0.1.1-n9s8TrF6UHQ8RXNcwP1N18zWZr8FebYF6C3IVInlTVCMQoYiL.VQxqzpuxKJh6fovFnyai6MQBHF70TbPr8aicW_KDHYcwWwECIAHQZWN4azs1IfMjCIJBWIYBhC2acR; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:37:44 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2dd07c1eb25970-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:37:44,870 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:37:44,870 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:07:44 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5925', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '750ms', 'x-request-id': 'req_01kj7ef2cqe01sw14ptgkd7gpj', 'via': '1.1 google', 'set-cookie': '__cf_bm=pJdhMDOkiSAxlisbv1iHQ673qcXiLSo_MS8k1aeXsHM-1771924064.6540754-1.0.1.1-n9s8TrF6UHQ8RXNcwP1N18zWZr8FebYF6C3IVInlTVCMQoYiL.VQxqzpuxKJh6fovFnyai6MQBHF70TbPr8aicW_KDHYcwWwECIAHQZWN4azs1IfMjCIJBWIYBhC2acR; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:37:44 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2dd07c1eb25970-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:37:44,870 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:37:45,116 [DEBUG] receive_response_body.complete
2026-02-24 14:37:45,116 [DEBUG] response_closed.started
2026-02-24 14:37:45,116 [DEBUG] response_closed.complete
2026-02-24 14:39:13,097 [INFO] Boot Complete
2026-02-24 14:42:26,120 [INFO] Boot Seqeunce Started
2026-02-24 14:42:31,592 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-66524946-3bc2-42f2-87c8-59d7e9d3ce23', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'what is gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:42:31,639 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:42:31,639 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:42:31,673 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B24F1E2A10>
2026-02-24 14:42:31,674 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B24EEE8540> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:42:31,687 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B24F1E2AA0>
2026-02-24 14:42:31,700 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:42:31,700 [DEBUG] send_request_headers.complete
2026-02-24 14:42:31,700 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:42:31,702 [DEBUG] send_request_body.complete
2026-02-24 14:42:31,702 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:42:31,789 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:12:31 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5924'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'760ms'), (b'x-request-id', b'req_01kj7eqtjnezbbpn4tghd48avm'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'set-cookie', b'__cf_bm=iqg7X._s2rJQ5K7sXF0iBv7GrydeC.BQ46uSsjzSj_Y-1771924351.5662491-1.0.1.1-_PJh68eujH.gl9je1QTVRlfaBpEB5v9bQQeovmv82rYrwACuWcQBfkdpCNCB1esNYcEj6xqSTQVQmWV0H7sleFp7rENwIlU6W12AKkO256CCiZaizF3acH4LKa4qy3HU; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:42:31 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2dd77d4f2154d2-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:42:31,790 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:42:31,790 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:12:31 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5924', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '760ms', 'x-request-id': 'req_01kj7eqtjnezbbpn4tghd48avm', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=iqg7X._s2rJQ5K7sXF0iBv7GrydeC.BQ46uSsjzSj_Y-1771924351.5662491-1.0.1.1-_PJh68eujH.gl9je1QTVRlfaBpEB5v9bQQeovmv82rYrwACuWcQBfkdpCNCB1esNYcEj6xqSTQVQmWV0H7sleFp7rENwIlU6W12AKkO256CCiZaizF3acH4LKa4qy3HU; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:42:31 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2dd77d4f2154d2-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:42:31,790 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:42:31,855 [DEBUG] receive_response_body.complete
2026-02-24 14:42:31,855 [DEBUG] response_closed.started
2026-02-24 14:42:31,855 [DEBUG] response_closed.complete
2026-02-24 14:44:26,060 [INFO] Boot Complete
2026-02-24 14:44:29,477 [INFO] Boot Seqeunce Started
2026-02-24 14:44:33,669 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ed8d5603-0db7-4f12-96eb-e9a6b84a0e24', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'what is gravity?'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:44:33,715 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:44:33,716 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:44:33,751 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002366E37B790>
2026-02-24 14:44:33,751 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000002366E200AC0> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:44:33,751 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002366E37B820>
2026-02-24 14:44:33,751 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:44:33,751 [DEBUG] send_request_headers.complete
2026-02-24 14:44:33,751 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:44:33,751 [DEBUG] send_request_body.complete
2026-02-24 14:44:33,751 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:44:33,864 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:14:33 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5923'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'770ms'), (b'x-request-id', b'req_01kj7evhsge448f99qe9zxydxz'), (b'via', b'1.1 google'), (b'set-cookie', b'__cf_bm=Zb1yGNiVMT60vinoarmH4yZKCT79oPgV6nIFnpN8BEI-1771924473.6261878-1.0.1.1-ITa78WFQafxtmhSwPt6b6z7TEm7x6ZHiIluzfo7v1qw_iZpoHYHHayFg6kYZBfi8oJ6BsOxLCinHuJaGkvj4cZbt7Jl8uYntLyj2uiE9MRBmqKSI25hnWjBdCeR95S9l; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:44:33 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2dda782fd2dfdc-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:44:33,864 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:44:33,864 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:14:33 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5923', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '770ms', 'x-request-id': 'req_01kj7evhsge448f99qe9zxydxz', 'via': '1.1 google', 'set-cookie': '__cf_bm=Zb1yGNiVMT60vinoarmH4yZKCT79oPgV6nIFnpN8BEI-1771924473.6261878-1.0.1.1-ITa78WFQafxtmhSwPt6b6z7TEm7x6ZHiIluzfo7v1qw_iZpoHYHHayFg6kYZBfi8oJ6BsOxLCinHuJaGkvj4cZbt7Jl8uYntLyj2uiE9MRBmqKSI25hnWjBdCeR95S9l; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:44:33 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2dda782fd2dfdc-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:44:33,864 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:44:33,967 [DEBUG] receive_response_body.complete
2026-02-24 14:44:33,968 [DEBUG] response_closed.started
2026-02-24 14:44:33,968 [DEBUG] response_closed.complete
2026-02-24 14:45:01,163 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-7563a62a-5823-4e2e-b12d-acb6150bd321', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'what is gravity?'}, {'role': 'assistant', 'content': "Gravity is a fundamental force of nature that attracts objects towards each other. It's a result of the interaction between two masses, causing a force that's proportional to their mass and distance apart. According to Einstein's theory of general relativity, gravity is the curvature of spacetime caused by massive objects."}, {'role': 'user', 'content': 'what is the meaning of integration with respect to 3d objects?'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:45:01,164 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:45:01,164 [DEBUG] close.started
2026-02-24 14:45:01,165 [DEBUG] close.complete
2026-02-24 14:45:01,165 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:45:01,173 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002366E3B1870>
2026-02-24 14:45:01,174 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000002366E200AC0> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:45:01,182 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002366E3B17B0>
2026-02-24 14:45:01,182 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:45:01,182 [DEBUG] send_request_headers.complete
2026-02-24 14:45:01,182 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:45:01,182 [DEBUG] send_request_body.complete
2026-02-24 14:45:01,182 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:45:01,274 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:15:01 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5839'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'1.61s'), (b'x-request-id', b'req_01kj7ewcj1e5jb6311fzc2vzkm'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2ddb239debe067-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:45:01,274 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:45:01,274 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:15:01 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5839', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '1.61s', 'x-request-id': 'req_01kj7ewcj1e5jb6311fzc2vzkm', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2ddb239debe067-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:45:01,275 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:45:01,447 [DEBUG] receive_response_body.complete
2026-02-24 14:45:01,447 [DEBUG] response_closed.started
2026-02-24 14:45:01,447 [DEBUG] response_closed.complete
2026-02-24 14:45:18,506 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-173682b4-799a-49eb-a457-9e9b8117925f', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'what is gravity?'}, {'role': 'assistant', 'content': "Gravity is a fundamental force of nature that attracts objects towards each other. It's a result of the interaction between two masses, causing a force that's proportional to their mass and distance apart. According to Einstein's theory of general relativity, gravity is the curvature of spacetime caused by massive objects."}, {'role': 'user', 'content': 'what is the meaning of integration with respect to 3d objects?'}, {'role': 'assistant', 'content': "Integration with respect to 3D objects refers to calculating the volume of an object (such as a sphere, cylinder, or pyramid) by integrating the function that describes its shape over its boundaries.\n\nIn mathematical terms, it's a triple integral (dx dy dz) that sums up volumes in the x-y-z coordinate planes, allowing the calculation of the total volume occupied by the object."}, {'role': 'user', 'content': 'write 100 words. any.'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:45:18,507 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:45:18,507 [DEBUG] close.started
2026-02-24 14:45:18,507 [DEBUG] close.complete
2026-02-24 14:45:18,507 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:45:18,528 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002366E3B31F0>
2026-02-24 14:45:18,528 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000002366E200AC0> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:45:18,535 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002366E3B3160>
2026-02-24 14:45:18,535 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:45:18,543 [DEBUG] send_request_headers.complete
2026-02-24 14:45:18,543 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:45:18,543 [DEBUG] send_request_body.complete
2026-02-24 14:45:18,543 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:45:18,613 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:15:18 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5745'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'2.55s'), (b'x-request-id', b'req_01kj7ewxgbf80rdez2btkmtd2d'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2ddb9009980186-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:45:18,613 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:45:18,613 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:15:18 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5745', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '2.55s', 'x-request-id': 'req_01kj7ewxgbf80rdez2btkmtd2d', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2ddb9009980186-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:45:18,613 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:45:18,847 [DEBUG] receive_response_body.complete
2026-02-24 14:45:18,847 [DEBUG] response_closed.started
2026-02-24 14:45:18,847 [DEBUG] response_closed.complete
2026-02-24 14:46:08,899 [INFO] Boot Complete
2026-02-24 14:48:26,231 [INFO] Boot Seqeunce Started
2026-02-24 14:48:34,001 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-bb0176db-4141-41dc-a02c-f73eab8545d8', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain gravity to me'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:48:34,026 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:48:34,042 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:48:34,074 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001940851B790>
2026-02-24 14:48:34,074 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x00000194083A0AC0> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:48:34,089 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001940851B820>
2026-02-24 14:48:34,089 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:48:34,089 [DEBUG] send_request_headers.complete
2026-02-24 14:48:34,089 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:48:34,091 [DEBUG] send_request_body.complete
2026-02-24 14:48:34,091 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:48:34,176 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:18:34 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5923'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'770ms'), (b'x-request-id', b'req_01kj7f2wf9ej3bb7qq0h46nee9'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'set-cookie', b'__cf_bm=D70SXsYmd7IT1UO7.Kcvwg8QeU8Ir5NVsPMlBuu1SEE-1771924713.9532096-1.0.1.1-6hcpo5R_g4XI.BLc9ezdkn42KYzuYjzbauTr.Oe5XkU9FgeQbI80v4aHsc97v5Bj.PTxDlg_ZmCZGp1z0h45J29fv0KNuiBkO3YAjePU7NBQSWrsd6kcYuVqoLvOvwPE; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:48:34 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2de0563b3554fb-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:48:34,176 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:48:34,176 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:18:34 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5923', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '770ms', 'x-request-id': 'req_01kj7f2wf9ej3bb7qq0h46nee9', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=D70SXsYmd7IT1UO7.Kcvwg8QeU8Ir5NVsPMlBuu1SEE-1771924713.9532096-1.0.1.1-6hcpo5R_g4XI.BLc9ezdkn42KYzuYjzbauTr.Oe5XkU9FgeQbI80v4aHsc97v5Bj.PTxDlg_ZmCZGp1z0h45J29fv0KNuiBkO3YAjePU7NBQSWrsd6kcYuVqoLvOvwPE; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:48:34 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2de0563b3554fb-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:48:34,176 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:48:34,248 [DEBUG] receive_response_body.complete
2026-02-24 14:48:34,250 [DEBUG] response_closed.started
2026-02-24 14:48:34,250 [DEBUG] response_closed.complete
2026-02-24 14:48:37,698 [INFO] Boot Complete
2026-02-24 14:51:40,717 [INFO] Boot Seqeunce Started
2026-02-24 14:51:44,940 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-63110b68-408d-4970-8c5c-551dd3bd4152', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:51:44,966 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:51:44,966 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:51:45,030 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000158BD9AB6D0>
2026-02-24 14:51:45,030 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x00000158BD830B40> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:51:45,041 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000158BD9AB760>
2026-02-24 14:51:45,042 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:51:45,042 [DEBUG] send_request_headers.complete
2026-02-24 14:51:45,042 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:51:45,042 [DEBUG] send_request_body.complete
2026-02-24 14:51:45,042 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:51:45,114 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:21:44 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5925'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'750ms'), (b'x-request-id', b'req_01kj7f8pyafxxs0gzhbdn50be7'), (b'via', b'1.1 google'), (b'set-cookie', b'__cf_bm=_PB8a0MbcxnWFAAOVVX60OXJmb8_s.uKfiMurrl.njQ-1771924904.8998477-1.0.1.1-ZAkS3aSEAzj1tc0xWsBlAkw08.6uHtaML6Xhy0hg.4L04FDzgnVZNFnjRn4dbIaaUorUFZyILHTrTmFrxFRj7anxyXqh90Sd2rrfyF8yz1DbEFMDNa1Buhbv_VDFRjcl; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:51:44 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2de4ff9c7a1e0a-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:51:45,114 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:51:45,114 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:21:44 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5925', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '750ms', 'x-request-id': 'req_01kj7f8pyafxxs0gzhbdn50be7', 'via': '1.1 google', 'set-cookie': '__cf_bm=_PB8a0MbcxnWFAAOVVX60OXJmb8_s.uKfiMurrl.njQ-1771924904.8998477-1.0.1.1-ZAkS3aSEAzj1tc0xWsBlAkw08.6uHtaML6Xhy0hg.4L04FDzgnVZNFnjRn4dbIaaUorUFZyILHTrTmFrxFRj7anxyXqh90Sd2rrfyF8yz1DbEFMDNa1Buhbv_VDFRjcl; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:51:44 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2de4ff9c7a1e0a-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:51:45,114 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:51:45,334 [DEBUG] receive_response_body.complete
2026-02-24 14:51:45,334 [DEBUG] response_closed.started
2026-02-24 14:51:45,334 [DEBUG] response_closed.complete
2026-02-24 14:51:52,737 [INFO] Boot Complete
2026-02-24 14:51:52,939 [DEBUG] close.started
2026-02-24 14:51:52,939 [DEBUG] close.complete
2026-02-24 14:52:05,091 [INFO] Boot Seqeunce Started
2026-02-24 14:52:16,548 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-3efcf69a-6207-4a73-84c1-a858413c83dd', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'my text-to-speech module often skips the first sentence you speak. any idea why?'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:52:16,599 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:52:16,599 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:52:16,616 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001625B91B6A0>
2026-02-24 14:52:16,616 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000001625B7A0B40> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:52:16,629 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001625B91B730>
2026-02-24 14:52:16,630 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:52:16,630 [DEBUG] send_request_headers.complete
2026-02-24 14:52:16,630 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:52:16,630 [DEBUG] send_request_body.complete
2026-02-24 14:52:16,630 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:52:16,712 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:22:16 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5909'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'910ms'), (b'x-request-id', b'req_01kj7f9nsffmjrkd7vpfs8k79n'), (b'via', b'1.1 google'), (b'set-cookie', b'__cf_bm=z66fD2kj3teLq3BBhbDRM.8Ioyoh6f30a8XNwc_rtTE-1771924936.4880362-1.0.1.1-p_KQloaI8ttClmBDyROOCpDsA4hldQ5PwN4PuFEBOU6E1oWWKpdZ2G_YDkSqBZ6i8TTlGZcTMx2ahwhGkVmuU53BaHnmAPlyKr0BuEnndYnflAJ0GNSNkLpBqzrJP_5O; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:52:16 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2de5c5094491ce-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:52:16,712 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:52:16,712 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:22:16 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5909', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '910ms', 'x-request-id': 'req_01kj7f9nsffmjrkd7vpfs8k79n', 'via': '1.1 google', 'set-cookie': '__cf_bm=z66fD2kj3teLq3BBhbDRM.8Ioyoh6f30a8XNwc_rtTE-1771924936.4880362-1.0.1.1-p_KQloaI8ttClmBDyROOCpDsA4hldQ5PwN4PuFEBOU6E1oWWKpdZ2G_YDkSqBZ6i8TTlGZcTMx2ahwhGkVmuU53BaHnmAPlyKr0BuEnndYnflAJ0GNSNkLpBqzrJP_5O; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:52:16 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2de5c5094491ce-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:52:16,712 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:52:16,931 [DEBUG] receive_response_body.complete
2026-02-24 14:52:16,932 [DEBUG] response_closed.started
2026-02-24 14:52:16,932 [DEBUG] response_closed.complete
2026-02-24 14:52:29,749 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-a916c0ac-937d-4b60-8acd-a2c144665dd4', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'my text-to-speech module often skips the first sentence you speak. any idea why?'}, {'role': 'assistant', 'content': 'Possible causes:\n\n1. **Timing issues**: Ensure your text-to-speech (TTS) module is synchronized properly with the audio playback.\n2. **Triggering**: Check if the TTS module is being triggered incorrectly, causing the first sentence to be cut off.\n3. **Buffering**: Verify that the audio buffer is not too small, leading to skipping of the initial audio.\n\nTo troubleshoot:\n- Review your code and audio configuration.\n- Check for any recent updates that could be affecting the TTS module.\n- Test with different audio playback options or libraries.'}, {'role': 'user', 'content': 'asd'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:52:29,754 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:52:29,754 [DEBUG] close.started
2026-02-24 14:52:29,754 [DEBUG] close.complete
2026-02-24 14:52:29,754 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:52:29,765 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001625B955C00>
2026-02-24 14:52:29,765 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000001625B7A0B40> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:52:29,775 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001625B955BD0>
2026-02-24 14:52:29,775 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:52:29,775 [DEBUG] send_request_headers.complete
2026-02-24 14:52:29,775 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:52:29,775 [DEBUG] send_request_body.complete
2026-02-24 14:52:29,775 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:52:29,859 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:22:29 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5783'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'2.17s'), (b'x-request-id', b'req_01kj7fa2m4fn6bqqxtc9ed14sp'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2de6173b99b21e-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:52:29,859 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:52:29,859 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:22:29 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5783', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '2.17s', 'x-request-id': 'req_01kj7fa2m4fn6bqqxtc9ed14sp', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2de6173b99b21e-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:52:29,859 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:52:29,913 [DEBUG] receive_response_body.complete
2026-02-24 14:52:29,913 [DEBUG] response_closed.started
2026-02-24 14:52:29,914 [DEBUG] response_closed.complete
2026-02-24 14:52:31,934 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-a70258f6-7aea-4034-ad25-a71fb9aed02b', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'my text-to-speech module often skips the first sentence you speak. any idea why?'}, {'role': 'assistant', 'content': 'Possible causes:\n\n1. **Timing issues**: Ensure your text-to-speech (TTS) module is synchronized properly with the audio playback.\n2. **Triggering**: Check if the TTS module is being triggered incorrectly, causing the first sentence to be cut off.\n3. **Buffering**: Verify that the audio buffer is not too small, leading to skipping of the initial audio.\n\nTo troubleshoot:\n- Review your code and audio configuration.\n- Check for any recent updates that could be affecting the TTS module.\n- Test with different audio playback options or libraries.'}, {'role': 'user', 'content': 'asd'}, {'role': 'assistant', 'content': 'It seems like you entered random characters. No action required.'}, {'role': 'user', 'content': 'shut'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:52:31,939 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:52:31,939 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:52:31,939 [DEBUG] send_request_headers.complete
2026-02-24 14:52:31,939 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:52:31,939 [DEBUG] send_request_body.complete
2026-02-24 14:52:31,939 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:52:32,039 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:22:31 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'5747'), (b'x-ratelimit-reset-requests', b'12s'), (b'x-ratelimit-reset-tokens', b'2.53s'), (b'x-request-id', b'req_01kj7fa4r8ezxtdk75j5m4etb8'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2de624dce6b21e-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:52:32,039 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:52:32,039 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:22:31 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '5747', 'x-ratelimit-reset-requests': '12s', 'x-ratelimit-reset-tokens': '2.53s', 'x-request-id': 'req_01kj7fa4r8ezxtdk75j5m4etb8', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2de624dce6b21e-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:52:32,039 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:52:32,084 [DEBUG] receive_response_body.complete
2026-02-24 14:52:32,084 [DEBUG] response_closed.started
2026-02-24 14:52:32,084 [DEBUG] response_closed.complete
2026-02-24 14:52:33,697 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-558f53c4-3de3-4976-be13-c828323922c3', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'my text-to-speech module often skips the first sentence you speak. any idea why?'}, {'role': 'assistant', 'content': 'Possible causes:\n\n1. **Timing issues**: Ensure your text-to-speech (TTS) module is synchronized properly with the audio playback.\n2. **Triggering**: Check if the TTS module is being triggered incorrectly, causing the first sentence to be cut off.\n3. **Buffering**: Verify that the audio buffer is not too small, leading to skipping of the initial audio.\n\nTo troubleshoot:\n- Review your code and audio configuration.\n- Check for any recent updates that could be affecting the TTS module.\n- Test with different audio playback options or libraries.'}, {'role': 'user', 'content': 'asd'}, {'role': 'assistant', 'content': 'It seems like you entered random characters. No action required.'}, {'role': 'user', 'content': 'shut'}, {'role': 'assistant', 'content': 'Command not recognized. If you have a specific request, please rephrase it.'}, {'role': 'user', 'content': 'stop'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:52:33,698 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:52:33,698 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:52:33,698 [DEBUG] send_request_headers.complete
2026-02-24 14:52:33,698 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:52:33,699 [DEBUG] send_request_body.complete
2026-02-24 14:52:33,699 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:52:33,774 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:22:33 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14397'), (b'x-ratelimit-remaining-tokens', b'5636'), (b'x-ratelimit-reset-requests', b'18s'), (b'x-ratelimit-reset-tokens', b'3.64s'), (b'x-request-id', b'req_01kj7fa6epf0180fyf0h7dmmvd'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2de62fb8e4b21e-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:52:33,774 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:52:33,774 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:22:33 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14397', 'x-ratelimit-remaining-tokens': '5636', 'x-ratelimit-reset-requests': '18s', 'x-ratelimit-reset-tokens': '3.64s', 'x-request-id': 'req_01kj7fa6epf0180fyf0h7dmmvd', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2de62fb8e4b21e-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:52:33,774 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:52:33,802 [DEBUG] receive_response_body.complete
2026-02-24 14:52:33,802 [DEBUG] response_closed.started
2026-02-24 14:52:33,802 [DEBUG] response_closed.complete
2026-02-24 14:52:39,334 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-38a7ff98-e797-4319-b4d3-c8de1a7915dd', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'my text-to-speech module often skips the first sentence you speak. any idea why?'}, {'role': 'assistant', 'content': 'Possible causes:\n\n1. **Timing issues**: Ensure your text-to-speech (TTS) module is synchronized properly with the audio playback.\n2. **Triggering**: Check if the TTS module is being triggered incorrectly, causing the first sentence to be cut off.\n3. **Buffering**: Verify that the audio buffer is not too small, leading to skipping of the initial audio.\n\nTo troubleshoot:\n- Review your code and audio configuration.\n- Check for any recent updates that could be affecting the TTS module.\n- Test with different audio playback options or libraries.'}, {'role': 'user', 'content': 'asd'}, {'role': 'assistant', 'content': 'It seems like you entered random characters. No action required.'}, {'role': 'user', 'content': 'shut'}, {'role': 'assistant', 'content': 'Command not recognized. If you have a specific request, please rephrase it.'}, {'role': 'user', 'content': 'stop'}, {'role': 'assistant', 'content': 'Exiting interaction.'}, {'role': 'user', 'content': 'wow'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:52:39,334 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:52:39,334 [DEBUG] close.started
2026-02-24 14:52:39,334 [DEBUG] close.complete
2026-02-24 14:52:39,336 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:52:39,355 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001625B9B5AE0>
2026-02-24 14:52:39,356 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000001625B7A0B40> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:52:39,364 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001625B9B5B40>
2026-02-24 14:52:39,364 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:52:39,364 [DEBUG] send_request_headers.complete
2026-02-24 14:52:39,364 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:52:39,364 [DEBUG] send_request_body.complete
2026-02-24 14:52:39,364 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:52:39,448 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:22:39 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14396'), (b'x-ratelimit-remaining-tokens', b'5718'), (b'x-ratelimit-reset-requests', b'24s'), (b'x-ratelimit-reset-tokens', b'2.82s'), (b'x-request-id', b'req_01kj7fabzye0q9wges61e22b8e'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2de65328e32974-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:52:39,448 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:52:39,448 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:22:39 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14396', 'x-ratelimit-remaining-tokens': '5718', 'x-ratelimit-reset-requests': '24s', 'x-ratelimit-reset-tokens': '2.82s', 'x-request-id': 'req_01kj7fabzye0q9wges61e22b8e', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2de65328e32974-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:52:39,448 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:52:39,484 [DEBUG] receive_response_body.complete
2026-02-24 14:52:39,484 [DEBUG] response_closed.started
2026-02-24 14:52:39,484 [DEBUG] response_closed.complete
2026-02-24 14:52:40,024 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-f958550c-502f-4c00-bdfd-1b33e8a15f75', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'my text-to-speech module often skips the first sentence you speak. any idea why?'}, {'role': 'assistant', 'content': 'Possible causes:\n\n1. **Timing issues**: Ensure your text-to-speech (TTS) module is synchronized properly with the audio playback.\n2. **Triggering**: Check if the TTS module is being triggered incorrectly, causing the first sentence to be cut off.\n3. **Buffering**: Verify that the audio buffer is not too small, leading to skipping of the initial audio.\n\nTo troubleshoot:\n- Review your code and audio configuration.\n- Check for any recent updates that could be affecting the TTS module.\n- Test with different audio playback options or libraries.'}, {'role': 'user', 'content': 'asd'}, {'role': 'assistant', 'content': 'It seems like you entered random characters. No action required.'}, {'role': 'user', 'content': 'shut'}, {'role': 'assistant', 'content': 'Command not recognized. If you have a specific request, please rephrase it.'}, {'role': 'user', 'content': 'stop'}, {'role': 'assistant', 'content': 'Exiting interaction.'}, {'role': 'user', 'content': 'wow'}, {'role': 'assistant', 'content': 'No response. Interaction terminated.'}, {'role': 'user', 'content': 'ok'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:52:40,024 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:52:40,024 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:52:40,024 [DEBUG] send_request_headers.complete
2026-02-24 14:52:40,024 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:52:40,024 [DEBUG] send_request_body.complete
2026-02-24 14:52:40,026 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:52:40,111 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:22:39 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14395'), (b'x-ratelimit-remaining-tokens', b'5478'), (b'x-ratelimit-reset-requests', b'30s'), (b'x-ratelimit-reset-tokens', b'5.22s'), (b'x-request-id', b'req_01kj7facmke0qtgx1x4ct5h2yn'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2de657482d2974-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:52:40,111 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:52:40,112 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:22:39 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14395', 'x-ratelimit-remaining-tokens': '5478', 'x-ratelimit-reset-requests': '30s', 'x-ratelimit-reset-tokens': '5.22s', 'x-request-id': 'req_01kj7facmke0qtgx1x4ct5h2yn', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2de657482d2974-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:52:40,112 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:52:40,147 [DEBUG] receive_response_body.complete
2026-02-24 14:52:40,147 [DEBUG] response_closed.started
2026-02-24 14:52:40,147 [DEBUG] response_closed.complete
2026-02-24 14:52:41,472 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2f68e6a0-051b-4309-8112-0c3c83e02692', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'my text-to-speech module often skips the first sentence you speak. any idea why?'}, {'role': 'assistant', 'content': 'Possible causes:\n\n1. **Timing issues**: Ensure your text-to-speech (TTS) module is synchronized properly with the audio playback.\n2. **Triggering**: Check if the TTS module is being triggered incorrectly, causing the first sentence to be cut off.\n3. **Buffering**: Verify that the audio buffer is not too small, leading to skipping of the initial audio.\n\nTo troubleshoot:\n- Review your code and audio configuration.\n- Check for any recent updates that could be affecting the TTS module.\n- Test with different audio playback options or libraries.'}, {'role': 'user', 'content': 'asd'}, {'role': 'assistant', 'content': 'It seems like you entered random characters. No action required.'}, {'role': 'user', 'content': 'shut'}, {'role': 'assistant', 'content': 'Command not recognized. If you have a specific request, please rephrase it.'}, {'role': 'user', 'content': 'stop'}, {'role': 'assistant', 'content': 'Exiting interaction.'}, {'role': 'user', 'content': 'wow'}, {'role': 'assistant', 'content': 'No response. Interaction terminated.'}, {'role': 'user', 'content': 'ok'}, {'role': 'assistant', 'content': 'Terminated interaction remains concluded.'}, {'role': 'user', 'content': 'hmm'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:52:41,473 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:52:41,473 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:52:41,473 [DEBUG] send_request_headers.complete
2026-02-24 14:52:41,473 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:52:41,473 [DEBUG] send_request_body.complete
2026-02-24 14:52:41,473 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:52:41,562 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:22:41 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14394'), (b'x-ratelimit-remaining-tokens', b'5299'), (b'x-ratelimit-reset-requests', b'36s'), (b'x-ratelimit-reset-tokens', b'7.01s'), (b'x-request-id', b'req_01kj7fae1xe0t9q3z4a32qhgft'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2de66058362974-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:52:41,562 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:52:41,562 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:22:41 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14394', 'x-ratelimit-remaining-tokens': '5299', 'x-ratelimit-reset-requests': '36s', 'x-ratelimit-reset-tokens': '7.01s', 'x-request-id': 'req_01kj7fae1xe0t9q3z4a32qhgft', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2de66058362974-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:52:41,562 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:52:41,596 [DEBUG] receive_response_body.complete
2026-02-24 14:52:41,596 [DEBUG] response_closed.started
2026-02-24 14:52:41,596 [DEBUG] response_closed.complete
2026-02-24 14:52:42,825 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-1235b070-5305-47bb-a6cd-663eb43da2db', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'my text-to-speech module often skips the first sentence you speak. any idea why?'}, {'role': 'assistant', 'content': 'Possible causes:\n\n1. **Timing issues**: Ensure your text-to-speech (TTS) module is synchronized properly with the audio playback.\n2. **Triggering**: Check if the TTS module is being triggered incorrectly, causing the first sentence to be cut off.\n3. **Buffering**: Verify that the audio buffer is not too small, leading to skipping of the initial audio.\n\nTo troubleshoot:\n- Review your code and audio configuration.\n- Check for any recent updates that could be affecting the TTS module.\n- Test with different audio playback options or libraries.'}, {'role': 'user', 'content': 'asd'}, {'role': 'assistant', 'content': 'It seems like you entered random characters. No action required.'}, {'role': 'user', 'content': 'shut'}, {'role': 'assistant', 'content': 'Command not recognized. If you have a specific request, please rephrase it.'}, {'role': 'user', 'content': 'stop'}, {'role': 'assistant', 'content': 'Exiting interaction.'}, {'role': 'user', 'content': 'wow'}, {'role': 'assistant', 'content': 'No response. Interaction terminated.'}, {'role': 'user', 'content': 'ok'}, {'role': 'assistant', 'content': 'Terminated interaction remains concluded.'}, {'role': 'user', 'content': 'hmm'}, {'role': 'assistant', 'content': 'No action taken. Interaction is closed.'}, {'role': 'user', 'content': 'damn'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:52:42,825 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:52:42,834 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:52:42,834 [DEBUG] send_request_headers.complete
2026-02-24 14:52:42,834 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:52:42,834 [DEBUG] send_request_body.complete
2026-02-24 14:52:42,834 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:52:42,919 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:22:42 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14393'), (b'x-ratelimit-remaining-tokens', b'5090'), (b'x-ratelimit-reset-requests', b'42s'), (b'x-ratelimit-reset-tokens', b'9.1s'), (b'x-request-id', b'req_01kj7fafc7fnxrmaektapbd9jh'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2de668df4b2974-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:52:42,919 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:52:42,919 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:22:42 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14393', 'x-ratelimit-remaining-tokens': '5090', 'x-ratelimit-reset-requests': '42s', 'x-ratelimit-reset-tokens': '9.1s', 'x-request-id': 'req_01kj7fafc7fnxrmaektapbd9jh', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2de668df4b2974-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:52:42,920 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:52:42,946 [DEBUG] receive_response_body.complete
2026-02-24 14:52:42,946 [DEBUG] response_closed.started
2026-02-24 14:52:42,946 [DEBUG] response_closed.complete
2026-02-24 14:52:47,307 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-7be4a872-5581-482c-82da-f17010830612', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'my text-to-speech module often skips the first sentence you speak. any idea why?'}, {'role': 'assistant', 'content': 'Possible causes:\n\n1. **Timing issues**: Ensure your text-to-speech (TTS) module is synchronized properly with the audio playback.\n2. **Triggering**: Check if the TTS module is being triggered incorrectly, causing the first sentence to be cut off.\n3. **Buffering**: Verify that the audio buffer is not too small, leading to skipping of the initial audio.\n\nTo troubleshoot:\n- Review your code and audio configuration.\n- Check for any recent updates that could be affecting the TTS module.\n- Test with different audio playback options or libraries.'}, {'role': 'user', 'content': 'asd'}, {'role': 'assistant', 'content': 'It seems like you entered random characters. No action required.'}, {'role': 'user', 'content': 'shut'}, {'role': 'assistant', 'content': 'Command not recognized. If you have a specific request, please rephrase it.'}, {'role': 'user', 'content': 'stop'}, {'role': 'assistant', 'content': 'Exiting interaction.'}, {'role': 'user', 'content': 'wow'}, {'role': 'assistant', 'content': 'No response. Interaction terminated.'}, {'role': 'user', 'content': 'ok'}, {'role': 'assistant', 'content': 'Terminated interaction remains concluded.'}, {'role': 'user', 'content': 'hmm'}, {'role': 'assistant', 'content': 'No action taken. Interaction is closed.'}, {'role': 'user', 'content': 'damn'}, {'role': 'assistant', 'content': 'Interaction remains inactive.'}, {'role': 'user', 'content': 'wahts gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:52:47,307 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:52:47,307 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:52:47,307 [DEBUG] send_request_headers.complete
2026-02-24 14:52:47,307 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:52:47,307 [DEBUG] send_request_body.complete
2026-02-24 14:52:47,307 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:52:47,396 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:22:47 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14392'), (b'x-ratelimit-remaining-tokens', b'5178'), (b'x-ratelimit-reset-requests', b'48s'), (b'x-ratelimit-reset-tokens', b'8.22s'), (b'x-request-id', b'req_01kj7fakr5fp4bfsc8sm7ph56f'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2de684ce062974-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:52:47,396 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:52:47,396 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:22:47 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14392', 'x-ratelimit-remaining-tokens': '5178', 'x-ratelimit-reset-requests': '48s', 'x-ratelimit-reset-tokens': '8.22s', 'x-request-id': 'req_01kj7fakr5fp4bfsc8sm7ph56f', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2de684ce062974-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:52:47,396 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:52:47,457 [DEBUG] receive_response_body.complete
2026-02-24 14:52:47,457 [DEBUG] response_closed.started
2026-02-24 14:52:47,457 [DEBUG] response_closed.complete
2026-02-24 14:52:59,074 [INFO] Boot Complete
2026-02-24 14:55:40,058 [INFO] Boot Seqeunce Started
2026-02-24 14:55:42,614 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-84030a4a-4b10-4a57-aef0-f6d6fde457f1', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'what is gravity?'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:55:42,654 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:55:42,654 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:55:42,702 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028C2693B640>
2026-02-24 14:55:42,702 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028C267C0A40> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:55:42,718 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028C2693B6D0>
2026-02-24 14:55:42,718 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:55:42,718 [DEBUG] send_request_headers.complete
2026-02-24 14:55:42,718 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:55:42,718 [DEBUG] send_request_body.complete
2026-02-24 14:55:42,718 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:55:42,815 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:25:42 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5923'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'770ms'), (b'x-request-id', b'req_01kj7ffz1qfzyapdqrg67h7cfg'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'set-cookie', b'__cf_bm=VXMBDvL7Bb6nuyGN3GO89CcVnTnuH.y4mTpSmo6NOVE-1771925142.5755847-1.0.1.1-QVYz0HSsfHtMX9CQVGHm6cRUZwHWRarfpWGCWDZJQK0YT4L19lcalkPUyQiVgsbBnB8zCSmHDGSL3SkA.iBKOmlp5NLKMmpx7vF_V7VM8NIBEFVCvca2W9q.5p54v_Ja; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:55:42 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2deacd1fe05520-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:55:42,815 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:55:42,815 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:25:42 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5923', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '770ms', 'x-request-id': 'req_01kj7ffz1qfzyapdqrg67h7cfg', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=VXMBDvL7Bb6nuyGN3GO89CcVnTnuH.y4mTpSmo6NOVE-1771925142.5755847-1.0.1.1-QVYz0HSsfHtMX9CQVGHm6cRUZwHWRarfpWGCWDZJQK0YT4L19lcalkPUyQiVgsbBnB8zCSmHDGSL3SkA.iBKOmlp5NLKMmpx7vF_V7VM8NIBEFVCvca2W9q.5p54v_Ja; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:55:42 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2deacd1fe05520-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:55:42,815 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:55:42,928 [DEBUG] receive_response_body.complete
2026-02-24 14:55:42,928 [DEBUG] response_closed.started
2026-02-24 14:55:42,928 [DEBUG] response_closed.complete
2026-02-24 14:56:07,270 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-b44cf73f-d63c-4174-b94b-de09b97ecb0c', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'what is gravity?'}, {'role': 'assistant', 'content': "Gravity is a fundamental force in the universe that attracts two objects with mass towards each other. It's a result of warping space-time around massive objects, causing objects to follow geodesic paths towards the center of mass. Think of it as a universal pull that connects everything."}, {'role': 'user', 'content': 'hello??'}, {'role': 'assistant', 'content': 'Hello.'}, {'role': 'user', 'content': 'why arent you speaking'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:56:07,272 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:56:07,272 [DEBUG] close.started
2026-02-24 14:56:07,272 [DEBUG] close.complete
2026-02-24 14:56:07,272 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:56:07,297 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028C26974C70>
2026-02-24 14:56:07,297 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028C267C0A40> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:56:07,301 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028C26974790>
2026-02-24 14:56:07,301 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:56:07,301 [DEBUG] send_request_headers.complete
2026-02-24 14:56:07,301 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:56:07,301 [DEBUG] send_request_body.complete
2026-02-24 14:56:07,301 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:56:07,379 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:26:07 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5838'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'1.62s'), (b'x-request-id', b'req_01kj7fgq1zfc1bv1jrzea5bpa8'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2deb66ca0fedd1-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:56:07,379 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:56:07,379 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:26:07 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5838', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '1.62s', 'x-request-id': 'req_01kj7fgq1zfc1bv1jrzea5bpa8', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2deb66ca0fedd1-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:56:07,379 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:56:07,504 [DEBUG] receive_response_body.complete
2026-02-24 14:56:07,504 [DEBUG] response_closed.started
2026-02-24 14:56:07,504 [DEBUG] response_closed.complete
2026-02-24 14:56:14,936 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-0caad0ab-928d-4760-ab01-1116cece14d5', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'what is gravity?'}, {'role': 'assistant', 'content': "Gravity is a fundamental force in the universe that attracts two objects with mass towards each other. It's a result of warping space-time around massive objects, causing objects to follow geodesic paths towards the center of mass. Think of it as a universal pull that connects everything."}, {'role': 'user', 'content': 'hello??'}, {'role': 'assistant', 'content': 'Hello.'}, {'role': 'user', 'content': 'why arent you speaking'}, {'role': 'assistant', 'content': "I'm functioning normally. I may have paused briefly, but I'm ready to assist you now. If you have a specific topic or question, I'll respond with the information you need."}, {'role': 'user', 'content': "i can't hear you"}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:56:14,936 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:56:14,936 [DEBUG] close.started
2026-02-24 14:56:14,936 [DEBUG] close.complete
2026-02-24 14:56:14,936 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:56:14,970 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028C269767A0>
2026-02-24 14:56:14,971 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028C267C0A40> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:56:14,980 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028C269765C0>
2026-02-24 14:56:14,980 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:56:14,980 [DEBUG] send_request_headers.complete
2026-02-24 14:56:14,980 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:56:14,980 [DEBUG] send_request_body.complete
2026-02-24 14:56:14,980 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:56:15,054 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:26:14 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5785'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'2.15s'), (b'x-request-id', b'req_01kj7fgyhrfcf99rg78wns75mt'), (b'via', b'1.1 google'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2deb96bdd7087a-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:56:15,054 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:56:15,054 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:26:14 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5785', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '2.15s', 'x-request-id': 'req_01kj7fgyhrfcf99rg78wns75mt', 'via': '1.1 google', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2deb96bdd7087a-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:56:15,054 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:56:15,122 [DEBUG] receive_response_body.complete
2026-02-24 14:56:15,122 [DEBUG] response_closed.started
2026-02-24 14:56:15,122 [DEBUG] response_closed.complete
2026-02-24 14:56:20,444 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-20119e1a-de0c-4e00-89f2-9d4a9af3c534', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'what is gravity?'}, {'role': 'assistant', 'content': "Gravity is a fundamental force in the universe that attracts two objects with mass towards each other. It's a result of warping space-time around massive objects, causing objects to follow geodesic paths towards the center of mass. Think of it as a universal pull that connects everything."}, {'role': 'user', 'content': 'hello??'}, {'role': 'assistant', 'content': 'Hello.'}, {'role': 'user', 'content': 'why arent you speaking'}, {'role': 'assistant', 'content': "I'm functioning normally. I may have paused briefly, but I'm ready to assist you now. If you have a specific topic or question, I'll respond with the information you need."}, {'role': 'user', 'content': "i can't hear you"}, {'role': 'assistant', 'content': "It seems there's a communication issue. Are you using text or voice interface to interact with me?"}, {'role': 'user', 'content': 'text to speech'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:56:20,445 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:56:20,445 [DEBUG] close.started
2026-02-24 14:56:20,446 [DEBUG] close.complete
2026-02-24 14:56:20,446 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:56:20,475 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028C269D4040>
2026-02-24 14:56:20,475 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028C267C0A40> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:56:20,492 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028C269D40D0>
2026-02-24 14:56:20,492 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:56:20,492 [DEBUG] send_request_headers.complete
2026-02-24 14:56:20,492 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:56:20,492 [DEBUG] send_request_body.complete
2026-02-24 14:56:20,492 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:56:20,578 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:26:20 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'5752'), (b'x-ratelimit-reset-requests', b'12s'), (b'x-ratelimit-reset-tokens', b'2.48s'), (b'x-request-id', b'req_01kj7fh3y5ec6agnyghwd941a1'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2debb92fb854de-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:56:20,578 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:56:20,578 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:26:20 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '5752', 'x-ratelimit-reset-requests': '12s', 'x-ratelimit-reset-tokens': '2.48s', 'x-request-id': 'req_01kj7fh3y5ec6agnyghwd941a1', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2debb92fb854de-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:56:20,578 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:56:20,720 [DEBUG] receive_response_body.complete
2026-02-24 14:56:20,720 [DEBUG] response_closed.started
2026-02-24 14:56:20,720 [DEBUG] response_closed.complete
2026-02-24 14:58:44,459 [INFO] Boot Complete
2026-02-24 14:58:53,261 [INFO] Boot Seqeunce Started
2026-02-24 14:58:56,999 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-498ec422-4756-4c17-adb7-69b69328c091', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:58:57,049 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:58:57,049 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:58:57,083 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DE787FB730>
2026-02-24 14:58:57,083 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DE78680A40> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:58:57,115 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DE787FB7C0>
2026-02-24 14:58:57,115 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:58:57,115 [DEBUG] send_request_headers.complete
2026-02-24 14:58:57,115 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:58:57,115 [DEBUG] send_request_body.complete
2026-02-24 14:58:57,115 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:58:57,197 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:28:57 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5925'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'750ms'), (b'x-request-id', b'req_01kj7fnwwhfn5832fqwdm3skr8'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'set-cookie', b'__cf_bm=xiFKXgEgWz2_rLYzF4aDsDhIKJSg5RFlzckaMkOmH_0-1771925336.9689796-1.0.1.1-tU0oGFe.Q9ItvIOGeriKIRjb.IYDZf0lZdbOmz6A2fK28S90GpEiPJC3cY8zayhw2O..Ihk814XMWUHRFGudWfv0eYkyxRntb5X1EexvSrb3OcWDE8H1KdzYtVktKt19; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:58:57 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2def8c088a54f5-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:58:57,197 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:58:57,197 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:28:57 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5925', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '750ms', 'x-request-id': 'req_01kj7fnwwhfn5832fqwdm3skr8', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=xiFKXgEgWz2_rLYzF4aDsDhIKJSg5RFlzckaMkOmH_0-1771925336.9689796-1.0.1.1-tU0oGFe.Q9ItvIOGeriKIRjb.IYDZf0lZdbOmz6A2fK28S90GpEiPJC3cY8zayhw2O..Ihk814XMWUHRFGudWfv0eYkyxRntb5X1EexvSrb3OcWDE8H1KdzYtVktKt19; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:58:57 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2def8c088a54f5-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:58:57,197 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:58:57,292 [DEBUG] receive_response_body.complete
2026-02-24 14:58:57,292 [DEBUG] response_closed.started
2026-02-24 14:58:57,292 [DEBUG] response_closed.complete
2026-02-24 14:59:44,999 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-95ed2e83-4915-4cf0-95cb-43bbe0247bc3', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp, intelligent AI assistant. Respond concisely by default. Use clear, direct language. Avoid long explanations unless explicitly asked. Be confident and efficient.'}, {'role': 'user', 'content': 'explain gravity'}, {'role': 'assistant', 'content': "Gravity is a universal force that attracts two objects with mass towards each other. It's a result of the mass warping space and time around it, causing curvature. The more massive the objects, the stronger the gravitational pull. This force is responsible for keeping planets in orbit, holding galaxies together, and drawing objects towards each other."}, {'role': 'user', 'content': 'explain gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:59:44,999 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:59:44,999 [DEBUG] close.started
2026-02-24 14:59:44,999 [DEBUG] close.complete
2026-02-24 14:59:44,999 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:59:45,022 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DE788309D0>
2026-02-24 14:59:45,022 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DE78680A40> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:59:45,037 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DE78830C70>
2026-02-24 14:59:45,037 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:59:45,037 [DEBUG] send_request_headers.complete
2026-02-24 14:59:45,037 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:59:45,037 [DEBUG] send_request_body.complete
2026-02-24 14:59:45,037 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:59:45,129 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:29:44 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5847'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'1.529s'), (b'x-request-id', b'req_01kj7fqbp3fpd8a57hh319anqb'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2df0b79d4554f8-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:59:45,129 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:59:45,129 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:29:44 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5847', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '1.529s', 'x-request-id': 'req_01kj7fqbp3fpd8a57hh319anqb', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2df0b79d4554f8-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:59:45,129 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:59:45,314 [DEBUG] receive_response_body.complete
2026-02-24 14:59:45,314 [DEBUG] response_closed.started
2026-02-24 14:59:45,314 [DEBUG] response_closed.complete
2026-02-24 14:59:48,350 [INFO] Boot Complete
2026-02-24 14:59:50,530 [INFO] Boot Seqeunce Started
2026-02-24 14:59:55,066 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-cb4af971-d648-47bd-a125-e4c4b1491f62', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp and intelligent AI assistant. Respond concisely but clearly. Use 24 short sentences unless detailed explanation is requested.'}, {'role': 'user', 'content': 'explain gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 14:59:55,114 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 14:59:55,114 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 14:59:55,135 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000212932CA7A0>
2026-02-24 14:59:55,135 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x00000212931587C0> server_hostname='api.groq.com' timeout=5.0
2026-02-24 14:59:55,144 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000212932CA830>
2026-02-24 14:59:55,144 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 14:59:55,144 [DEBUG] send_request_headers.complete
2026-02-24 14:59:55,150 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 14:59:55,150 [DEBUG] send_request_body.complete
2026-02-24 14:59:55,150 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 14:59:55,218 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:29:55 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5930'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'700ms'), (b'x-request-id', b'req_01kj7fqnhyerhaezzw94h3nv4g'), (b'via', b'1.1 google'), (b'set-cookie', b'__cf_bm=MWxoTMdDdF9jwdUo62xvBVHqC39PLSAsZrf8tjQo14g-1771925394.9981883-1.0.1.1-VJITo3G6g1glj9wr1ogmXrvnxYTycTL5XrEHRI9yt49PXVmqxdoTChkHJvxSAvuVlmYFLbaFI2duKoDy4h25bxLNwWv878Z5zKuo7KM_jo2YV9y5a9VT0C4OCFYI8EgF; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:59:55 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'cf-cache-status', b'DYNAMIC'), (b'CF-RAY', b'9d2df0f6b9dc5976-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 14:59:55,218 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 14:59:55,218 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:29:55 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5930', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '700ms', 'x-request-id': 'req_01kj7fqnhyerhaezzw94h3nv4g', 'via': '1.1 google', 'set-cookie': '__cf_bm=MWxoTMdDdF9jwdUo62xvBVHqC39PLSAsZrf8tjQo14g-1771925394.9981883-1.0.1.1-VJITo3G6g1glj9wr1ogmXrvnxYTycTL5XrEHRI9yt49PXVmqxdoTChkHJvxSAvuVlmYFLbaFI2duKoDy4h25bxLNwWv878Z5zKuo7KM_jo2YV9y5a9VT0C4OCFYI8EgF; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 09:59:55 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9d2df0f6b9dc5976-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 14:59:55,218 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 14:59:55,333 [DEBUG] receive_response_body.complete
2026-02-24 14:59:55,333 [DEBUG] response_closed.started
2026-02-24 14:59:55,333 [DEBUG] response_closed.complete
2026-02-24 14:59:58,562 [DEBUG] close.started
2026-02-24 14:59:58,563 [DEBUG] close.complete
2026-02-24 15:00:15,227 [INFO] Boot Seqeunce Started
2026-02-24 15:00:18,130 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-404b9726-7fc7-4b65-bf86-de5335f5003b', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp and intelligent AI assistant. Respond concisely but clearly. Use 24 short sentences unless detailed explanation is requested.'}, {'role': 'user', 'content': 'what is gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 15:00:18,180 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 15:00:18,180 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-24 15:00:18,214 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018DF8E0A710>
2026-02-24 15:00:18,214 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x0000018DF8C987C0> server_hostname='api.groq.com' timeout=5.0
2026-02-24 15:00:18,230 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018DF8E0A7A0>
2026-02-24 15:00:18,230 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 15:00:18,230 [DEBUG] send_request_headers.complete
2026-02-24 15:00:18,230 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 15:00:18,230 [DEBUG] send_request_body.complete
2026-02-24 15:00:18,230 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 15:00:18,313 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:30:18 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5929'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'710ms'), (b'x-request-id', b'req_01kj7frc3cet4tcm94x4af4ng7'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'set-cookie', b'__cf_bm=j9016BR8RyoGkNa6nDLajq__M9Y1rNfT2GYz.WF5yVw-1771925418.0827508-1.0.1.1-ttK9suwPUsrjXYvBCmCFQ1Xarw14OjgDSLeFhI3937.1oQa2AyoxVzlPKLXW.Fm5SVluMkupcvsSY7LJjujIONAY4MwDtKjP3sRXY8Abd7GUJWCRTE2Uk9JZfzzB9sxu; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 10:00:18 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2df1870cd25522-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 15:00:18,313 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 15:00:18,313 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:30:18 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '5929', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '710ms', 'x-request-id': 'req_01kj7frc3cet4tcm94x4af4ng7', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=j9016BR8RyoGkNa6nDLajq__M9Y1rNfT2GYz.WF5yVw-1771925418.0827508-1.0.1.1-ttK9suwPUsrjXYvBCmCFQ1Xarw14OjgDSLeFhI3937.1oQa2AyoxVzlPKLXW.Fm5SVluMkupcvsSY7LJjujIONAY4MwDtKjP3sRXY8Abd7GUJWCRTE2Uk9JZfzzB9sxu; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Tue, 24 Feb 2026 10:00:18 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2df1870cd25522-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 15:00:18,313 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 15:00:18,450 [DEBUG] receive_response_body.complete
2026-02-24 15:00:18,450 [DEBUG] response_closed.started
2026-02-24 15:00:18,451 [DEBUG] response_closed.complete
2026-02-24 15:00:20,148 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-b3442634-3ccb-44c9-bb3e-27ab30d2e1ce', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp and intelligent AI assistant. Respond concisely but clearly. Use 24 short sentences unless detailed explanation is requested.'}, {'role': 'user', 'content': 'what is gravity'}, {'role': 'assistant', 'content': "Gravity is a fundamental force of nature that attracts objects with mass towards each other. It is described by Albert Einstein's theory of General Relativity as the curvature of spacetime caused by massive objects. Gravity warps and distorts spacetime, making objects follow curved paths."}, {'role': 'user', 'content': 'what is mass'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-24 15:00:20,150 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-24 15:00:20,150 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-24 15:00:20,151 [DEBUG] send_request_headers.complete
2026-02-24 15:00:20,151 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-24 15:00:20,151 [DEBUG] send_request_body.complete
2026-02-24 15:00:20,151 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-24 15:00:20,237 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 24 Feb 2026 09:30:20 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'5862'), (b'x-ratelimit-reset-requests', b'12s'), (b'x-ratelimit-reset-tokens', b'1.38s'), (b'x-request-id', b'req_01kj7frdzcfqdr96ff7yd184pf'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d2df1930c185522-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-24 15:00:20,239 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-24 15:00:20,239 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Tue, 24 Feb 2026 09:30:20 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14398', 'x-ratelimit-remaining-tokens': '5862', 'x-ratelimit-reset-requests': '12s', 'x-ratelimit-reset-tokens': '1.38s', 'x-request-id': 'req_01kj7frdzcfqdr96ff7yd184pf', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d2df1930c185522-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-24 15:00:20,239 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-24 15:00:20,342 [DEBUG] receive_response_body.complete
2026-02-24 15:00:20,343 [DEBUG] response_closed.started
2026-02-24 15:00:20,343 [DEBUG] response_closed.complete
2026-02-24 15:00:24,208 [DEBUG] close.started
2026-02-24 15:00:24,208 [DEBUG] close.complete
2026-02-25 19:05:44,958 [INFO] Boot Seqeunce Started
2026-02-25 19:05:47,708 [DEBUG] Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fdb470ad-deff-4664-a6b8-3412be312fdb', 'json_data': {'messages': [{'role': 'system', 'content': 'You are CREED, a sharp and intelligent AI assistant. Respond concisely but clearly. Use 24 short sentences unless detailed explanation is requested.'}, {'role': 'user', 'content': 'explain gravity'}], 'model': 'llama-3.1-8b-instant', 'stream': True}}
2026-02-25 19:05:47,746 [DEBUG] Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2026-02-25 19:05:47,746 [DEBUG] connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2026-02-25 19:05:47,778 [DEBUG] connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000218F4C7EC20>
2026-02-25 19:05:47,778 [DEBUG] start_tls.started ssl_context=<ssl.SSLContext object at 0x00000218F4B0C740> server_hostname='api.groq.com' timeout=5.0
2026-02-25 19:05:47,778 [DEBUG] start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000218F4C7ECB0>
2026-02-25 19:05:47,778 [DEBUG] send_request_headers.started request=<Request [b'POST']>
2026-02-25 19:05:47,778 [DEBUG] send_request_headers.complete
2026-02-25 19:05:47,778 [DEBUG] send_request_body.started request=<Request [b'POST']>
2026-02-25 19:05:47,778 [DEBUG] send_request_body.complete
2026-02-25 19:05:47,778 [DEBUG] receive_response_headers.started request=<Request [b'POST']>
2026-02-25 19:05:47,877 [DEBUG] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 25 Feb 2026 13:35:47 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'no-cache'), (b'Server', b'cloudflare'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'4220'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'17.8s'), (b'x-request-id', b'req_01kjag6k9yexqv7yybb2czay07'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'set-cookie', b'__cf_bm=6lDeNTJRFkYBci0j6ldPeeTE2oQAxjOym4fWqjQjVkU-1772026547.4894297-1.0.1.1-EhvEgjij8IfiqAm.GYtwRDJYkKeNb3qeTnmiuOuo1Rmga2IfHjcKnDXKb8JtbuEqzlUZU915lWCw5xTSDa2zjNUzu6RHOCcUGmUpb_PsCIpY650NJuzJWFp8Jwk5i2Td; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Wed, 25 Feb 2026 14:05:47 GMT'), (b'Strict-Transport-Security', b'max-age=15552000'), (b'CF-RAY', b'9d379681cc0f24b2-DEL'), (b'alt-svc', b'h3=":443"; ma=86400')])
2026-02-25 19:05:47,877 [INFO] HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2026-02-25 19:05:47,877 [DEBUG] HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Wed, 25 Feb 2026 13:35:47 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cache-control': 'no-cache', 'server': 'cloudflare', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '14400', 'x-ratelimit-limit-tokens': '6000', 'x-ratelimit-remaining-requests': '14399', 'x-ratelimit-remaining-tokens': '4220', 'x-ratelimit-reset-requests': '6s', 'x-ratelimit-reset-tokens': '17.8s', 'x-request-id': 'req_01kjag6k9yexqv7yybb2czay07', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=6lDeNTJRFkYBci0j6ldPeeTE2oQAxjOym4fWqjQjVkU-1772026547.4894297-1.0.1.1-EhvEgjij8IfiqAm.GYtwRDJYkKeNb3qeTnmiuOuo1Rmga2IfHjcKnDXKb8JtbuEqzlUZU915lWCw5xTSDa2zjNUzu6RHOCcUGmUpb_PsCIpY650NJuzJWFp8Jwk5i2Td; HttpOnly; Secure; Path=/; Domain=groq.com; Expires=Wed, 25 Feb 2026 14:05:47 GMT', 'strict-transport-security': 'max-age=15552000', 'cf-ray': '9d379681cc0f24b2-DEL', 'alt-svc': 'h3=":443"; ma=86400'})
2026-02-25 19:05:47,878 [DEBUG] receive_response_body.started request=<Request [b'POST']>
2026-02-25 19:05:47,973 [DEBUG] receive_response_body.complete
2026-02-25 19:05:47,973 [DEBUG] response_closed.started
2026-02-25 19:05:47,973 [DEBUG] response_closed.complete
2026-02-25 19:06:00,408 [DEBUG] close.started
2026-02-25 19:06:00,408 [DEBUG] close.complete
